{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "sys.path.append(os.path.abspath(Path().resolve().parent/'src'))\n",
    "\n",
    "\n",
    "from kinematicsrobotics.model import Cluster\n",
    "from kinematicsrobotics.datahandler import Save, Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15324, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = Extract()\n",
    "ext._path_project = os.path.abspath(Path().resolve().parent)\n",
    "#dataset = ext.dataframe(r'src\\data\\raw\\dataset-semi-raw.csv')\n",
    "dataset = ext.dataframe(r'src\\data\\ready\\dataset-radius-0.5cm.csv')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = Cluster(data = dataset[['p_x','p_y','p_z']], \n",
    "                n_clusters = 4, \n",
    "                n_init = 'auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.hist(kmeans._model.labels_, bins=4, color='gray', edgecolor='black')\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "# Adicionar título e rótulos\n",
    "\n",
    "plt.xlabel(\"Valor\")\n",
    "plt.ylabel(\"Ocorrências\")\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# plt.bar(set(kmeans._model.labels_)+1, kmeans._model.labels_, color='gray', edgecolor='black')\n",
    "\n",
    "# # Adicionar título e rótulos\n",
    "\n",
    "# #  Adicionar títulos e rótulos\n",
    "# plt.title('Gráfico de Barras')\n",
    "# plt.xlabel('Categorias')\n",
    "# plt.ylabel('Valores')\n",
    "# # Exibir o gráfico\n",
    "# plt.show()\n",
    "(set(kmeans._model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinematicsrobotics.model import Model\n",
    "from kinematicsrobotics.model import Cluster\n",
    "from kinematicsrobotics.datahandler import Save, Extract\n",
    "from kinematicsrobotics.dataprocessing import Preprocessing\n",
    "\n",
    "class LocalModel:\n",
    "    def __init__(self, *, model_cluster: Cluster, data, **kw):\n",
    "        self._model_cluster = model_cluster\n",
    "        self.models(**kw)\n",
    "        self.clusters(data = data)\n",
    "    \n",
    "    \n",
    "    def models(self, **kw):\n",
    "        models = []\n",
    "        for k in self._model_cluster._class_cluster:\n",
    "            models.append(Model.mlp_regressor(**kw))\n",
    "        \n",
    "        self._models = models\n",
    "    \n",
    "    def set_model(self,**params):\n",
    "        for model in self._models:\n",
    "            model.set_model(**params)\n",
    "\n",
    "    def fit(self):\n",
    "        i = 0\n",
    "        for model in self._models:\n",
    "            x_train, x_test, y_train, y_test = self._data_processing[i].data_train_test\n",
    "            model.fit(x = x_train, y = y_train)\n",
    "            i +=1\n",
    "\n",
    "    def clusters(self, data):\n",
    "        clusteres = set(self._model_cluster._model.labels_)\n",
    "        data_clusters = []\n",
    "        for cluster in clusteres:\n",
    "            idex_labes = []\n",
    "            i = 0\n",
    "            for labels in self._model_cluster._model.labels_:\n",
    "                if labels == cluster:\n",
    "                    idex_labes.append(i)\n",
    "                i +=1\n",
    "            data_clusters.append(data.iloc[idex_labes])\n",
    "\n",
    "        self._data_clusters = data_clusters\n",
    "\n",
    "\n",
    "    def split(self, *, test_size = 0.1):\n",
    "        data_processing = []\n",
    "        for cluster in self._data_clusters:\n",
    "            data_processing.append(Preprocessing(dataset = cluster, \n",
    "                                    x_labels=['p_x', 'p_y','p_z', 'roll', 'pich', 'yaw'],\n",
    "                                    y_labels=['theta_1', 'theta_2', 'theta_3', 'theta_4'], \n",
    "                                    size_test = test_size\n",
    "                                    )\n",
    "            )\n",
    "        self._data_processing = data_processing\n",
    "            \n",
    "\n",
    "    # def predict(self,*, x):\n",
    "    #     return self._model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlps = LocalModel(model_cluster=kmeans,\n",
    "                  data = dataset,\n",
    "                  early_stopping=True, \n",
    "                  EPOCHS=1000, \n",
    "                  EPOCHS_NOCHANGE=30,\n",
    "                  random_state=42, \n",
    "                  verbose=True,\n",
    "                  hidden_layer_sizes = (320, 375, 265, 155),\n",
    "                  activation = 'relu'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlps.split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.26542087\n",
      "Validation score: 0.752008\n",
      "Iteration 2, loss = 0.09139036\n",
      "Validation score: 0.910725\n",
      "Iteration 3, loss = 0.05170888\n",
      "Validation score: 0.938287\n",
      "Iteration 4, loss = 0.03842586\n",
      "Validation score: 0.944709\n",
      "Iteration 5, loss = 0.03128252\n",
      "Validation score: 0.959359\n",
      "Iteration 6, loss = 0.02638250\n",
      "Validation score: 0.965313\n",
      "Iteration 7, loss = 0.02437103\n",
      "Validation score: 0.966160\n",
      "Iteration 8, loss = 0.02194744\n",
      "Validation score: 0.967730\n",
      "Iteration 9, loss = 0.02015274\n",
      "Validation score: 0.970552\n",
      "Iteration 10, loss = 0.01828884\n",
      "Validation score: 0.970636\n",
      "Iteration 11, loss = 0.01711792\n",
      "Validation score: 0.971762\n",
      "Iteration 12, loss = 0.01611829\n",
      "Validation score: 0.975777\n",
      "Iteration 13, loss = 0.01527279\n",
      "Validation score: 0.977654\n",
      "Iteration 14, loss = 0.01459863\n",
      "Validation score: 0.974914\n",
      "Iteration 15, loss = 0.01679515\n",
      "Validation score: 0.965390\n",
      "Iteration 16, loss = 0.01704523\n",
      "Validation score: 0.975997\n",
      "Iteration 17, loss = 0.01386383\n",
      "Validation score: 0.980005\n",
      "Iteration 18, loss = 0.01324598\n",
      "Validation score: 0.979571\n",
      "Iteration 19, loss = 0.01263094\n",
      "Validation score: 0.979022\n",
      "Iteration 20, loss = 0.01250111\n",
      "Validation score: 0.983108\n",
      "Iteration 21, loss = 0.01265361\n",
      "Validation score: 0.976830\n",
      "Iteration 22, loss = 0.01229996\n",
      "Validation score: 0.980871\n",
      "Iteration 23, loss = 0.01159080\n",
      "Validation score: 0.981788\n",
      "Iteration 24, loss = 0.01123525\n",
      "Validation score: 0.981985\n",
      "Iteration 25, loss = 0.01168124\n",
      "Validation score: 0.974602\n",
      "Iteration 26, loss = 0.01142584\n",
      "Validation score: 0.978810\n",
      "Iteration 27, loss = 0.01266902\n",
      "Validation score: 0.974337\n",
      "Iteration 28, loss = 0.01419910\n",
      "Validation score: 0.983057\n",
      "Iteration 29, loss = 0.01045264\n",
      "Validation score: 0.982505\n",
      "Iteration 30, loss = 0.00948598\n",
      "Validation score: 0.980259\n",
      "Iteration 31, loss = 0.01019888\n",
      "Validation score: 0.984754\n",
      "Iteration 32, loss = 0.00836905\n",
      "Validation score: 0.986515\n",
      "Iteration 33, loss = 0.00789682\n",
      "Validation score: 0.985717\n",
      "Iteration 34, loss = 0.00841036\n",
      "Validation score: 0.986595\n",
      "Iteration 35, loss = 0.00732750\n",
      "Validation score: 0.987832\n",
      "Iteration 36, loss = 0.00753563\n",
      "Validation score: 0.986127\n",
      "Iteration 37, loss = 0.00786243\n",
      "Validation score: 0.990045\n",
      "Iteration 38, loss = 0.00581662\n",
      "Validation score: 0.989757\n",
      "Iteration 39, loss = 0.00548115\n",
      "Validation score: 0.989702\n",
      "Iteration 40, loss = 0.00594273\n",
      "Validation score: 0.990077\n",
      "Iteration 41, loss = 0.00668369\n",
      "Validation score: 0.987791\n",
      "Iteration 42, loss = 0.00619468\n",
      "Validation score: 0.986999\n",
      "Iteration 43, loss = 0.00648627\n",
      "Validation score: 0.985115\n",
      "Iteration 44, loss = 0.00652115\n",
      "Validation score: 0.990325\n",
      "Iteration 45, loss = 0.00711023\n",
      "Validation score: 0.990897\n",
      "Iteration 46, loss = 0.00603750\n",
      "Validation score: 0.991665\n",
      "Iteration 47, loss = 0.00594464\n",
      "Validation score: 0.989256\n",
      "Iteration 48, loss = 0.00527349\n",
      "Validation score: 0.992216\n",
      "Iteration 49, loss = 0.00512718\n",
      "Validation score: 0.990986\n",
      "Iteration 50, loss = 0.00577191\n",
      "Validation score: 0.990029\n",
      "Iteration 51, loss = 0.00568947\n",
      "Validation score: 0.992708\n",
      "Iteration 52, loss = 0.00399867\n",
      "Validation score: 0.992422\n",
      "Iteration 53, loss = 0.00380957\n",
      "Validation score: 0.993564\n",
      "Iteration 54, loss = 0.00370768\n",
      "Validation score: 0.990889\n",
      "Iteration 55, loss = 0.00374053\n",
      "Validation score: 0.992313\n",
      "Iteration 56, loss = 0.00414630\n",
      "Validation score: 0.992615\n",
      "Iteration 57, loss = 0.00376388\n",
      "Validation score: 0.992088\n",
      "Iteration 58, loss = 0.00577724\n",
      "Validation score: 0.982249\n",
      "Iteration 59, loss = 0.00687988\n",
      "Validation score: 0.990405\n",
      "Iteration 60, loss = 0.00413721\n",
      "Validation score: 0.991085\n",
      "Iteration 61, loss = 0.00387950\n",
      "Validation score: 0.990357\n",
      "Iteration 62, loss = 0.00404242\n",
      "Validation score: 0.992767\n",
      "Iteration 63, loss = 0.00393171\n",
      "Validation score: 0.992035\n",
      "Iteration 64, loss = 0.00407369\n",
      "Validation score: 0.991864\n",
      "Iteration 65, loss = 0.00434097\n",
      "Validation score: 0.993693\n",
      "Iteration 66, loss = 0.00312219\n",
      "Validation score: 0.993055\n",
      "Iteration 67, loss = 0.00484816\n",
      "Validation score: 0.990946\n",
      "Iteration 68, loss = 0.00490170\n",
      "Validation score: 0.990608\n",
      "Iteration 69, loss = 0.00436811\n",
      "Validation score: 0.991937\n",
      "Iteration 70, loss = 0.00423946\n",
      "Validation score: 0.990481\n",
      "Iteration 71, loss = 0.00322766\n",
      "Validation score: 0.990686\n",
      "Iteration 72, loss = 0.00304374\n",
      "Validation score: 0.993746\n",
      "Iteration 73, loss = 0.00287539\n",
      "Validation score: 0.993440\n",
      "Iteration 74, loss = 0.00336062\n",
      "Validation score: 0.993891\n",
      "Iteration 75, loss = 0.00302179\n",
      "Validation score: 0.991962\n",
      "Iteration 76, loss = 0.00281848\n",
      "Validation score: 0.993309\n",
      "Iteration 77, loss = 0.00256901\n",
      "Validation score: 0.994329\n",
      "Iteration 78, loss = 0.00253653\n",
      "Validation score: 0.993211\n",
      "Iteration 79, loss = 0.00254867\n",
      "Validation score: 0.995097\n",
      "Iteration 80, loss = 0.00211824\n",
      "Validation score: 0.994881\n",
      "Iteration 81, loss = 0.00197050\n",
      "Validation score: 0.994899\n",
      "Iteration 82, loss = 0.00247664\n",
      "Validation score: 0.992797\n",
      "Iteration 83, loss = 0.00266522\n",
      "Validation score: 0.992120\n",
      "Iteration 84, loss = 0.00354204\n",
      "Validation score: 0.990121\n",
      "Iteration 85, loss = 0.00338037\n",
      "Validation score: 0.993475\n",
      "Iteration 86, loss = 0.00268388\n",
      "Validation score: 0.994580\n",
      "Iteration 87, loss = 0.00206475\n",
      "Validation score: 0.994450\n",
      "Iteration 88, loss = 0.00202416\n",
      "Validation score: 0.994043\n",
      "Iteration 89, loss = 0.00242882\n",
      "Validation score: 0.995002\n",
      "Iteration 90, loss = 0.00202402\n",
      "Validation score: 0.994704\n",
      "Iteration 91, loss = 0.00201147\n",
      "Validation score: 0.995142\n",
      "Iteration 92, loss = 0.00219843\n",
      "Validation score: 0.991900\n",
      "Iteration 93, loss = 0.00279864\n",
      "Validation score: 0.991631\n",
      "Iteration 94, loss = 0.00274364\n",
      "Validation score: 0.994563\n",
      "Iteration 95, loss = 0.00207239\n",
      "Validation score: 0.994542\n",
      "Iteration 96, loss = 0.00252980\n",
      "Validation score: 0.993937\n",
      "Iteration 97, loss = 0.00234621\n",
      "Validation score: 0.994476\n",
      "Iteration 98, loss = 0.00292366\n",
      "Validation score: 0.993970\n",
      "Iteration 99, loss = 0.00278659\n",
      "Validation score: 0.992647\n",
      "Iteration 100, loss = 0.00214979\n",
      "Validation score: 0.994629\n",
      "Iteration 101, loss = 0.00202207\n",
      "Validation score: 0.994078\n",
      "Iteration 102, loss = 0.00198647\n",
      "Validation score: 0.994656\n",
      "Iteration 103, loss = 0.00200026\n",
      "Validation score: 0.994504\n",
      "Iteration 104, loss = 0.00190648\n",
      "Validation score: 0.994851\n",
      "Iteration 105, loss = 0.00184163\n",
      "Validation score: 0.994753\n",
      "Iteration 106, loss = 0.00183167\n",
      "Validation score: 0.994840\n",
      "Iteration 107, loss = 0.00221698\n",
      "Validation score: 0.994390\n",
      "Iteration 108, loss = 0.00211496\n",
      "Validation score: 0.993480\n",
      "Iteration 109, loss = 0.00205021\n",
      "Validation score: 0.994596\n",
      "Iteration 110, loss = 0.00216783\n",
      "Validation score: 0.994885\n",
      "Validation score did not improve more than tol=0.000100 for 30 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.31274524\n",
      "Validation score: 0.731840\n",
      "Iteration 2, loss = 0.06830019\n",
      "Validation score: 0.888308\n",
      "Iteration 3, loss = 0.03652879\n",
      "Validation score: 0.935944\n",
      "Iteration 4, loss = 0.02140372\n",
      "Validation score: 0.967174\n",
      "Iteration 5, loss = 0.01276426\n",
      "Validation score: 0.974434\n",
      "Iteration 6, loss = 0.00980083\n",
      "Validation score: 0.980088\n",
      "Iteration 7, loss = 0.00786036\n",
      "Validation score: 0.977943\n",
      "Iteration 8, loss = 0.00720365\n",
      "Validation score: 0.988078\n",
      "Iteration 9, loss = 0.00548708\n",
      "Validation score: 0.987442\n",
      "Iteration 10, loss = 0.00471052\n",
      "Validation score: 0.987834\n",
      "Iteration 11, loss = 0.00461355\n",
      "Validation score: 0.990650\n",
      "Iteration 12, loss = 0.00387923\n",
      "Validation score: 0.987197\n",
      "Iteration 13, loss = 0.00402064\n",
      "Validation score: 0.990805\n",
      "Iteration 14, loss = 0.00304665\n",
      "Validation score: 0.991823\n",
      "Iteration 15, loss = 0.00278928\n",
      "Validation score: 0.992462\n",
      "Iteration 16, loss = 0.00296408\n",
      "Validation score: 0.992364\n",
      "Iteration 17, loss = 0.00304570\n",
      "Validation score: 0.992330\n",
      "Iteration 18, loss = 0.00236952\n",
      "Validation score: 0.992828\n",
      "Iteration 19, loss = 0.00231900\n",
      "Validation score: 0.993161\n",
      "Iteration 20, loss = 0.00296305\n",
      "Validation score: 0.989641\n",
      "Iteration 21, loss = 0.00327823\n",
      "Validation score: 0.992204\n",
      "Iteration 22, loss = 0.00237337\n",
      "Validation score: 0.993572\n",
      "Iteration 23, loss = 0.00247084\n",
      "Validation score: 0.991349\n",
      "Iteration 24, loss = 0.00281446\n",
      "Validation score: 0.993175\n",
      "Iteration 25, loss = 0.00298942\n",
      "Validation score: 0.986896\n",
      "Iteration 26, loss = 0.00384200\n",
      "Validation score: 0.988897\n",
      "Iteration 27, loss = 0.00361739\n",
      "Validation score: 0.993745\n",
      "Iteration 28, loss = 0.00312819\n",
      "Validation score: 0.989339\n",
      "Iteration 29, loss = 0.00333593\n",
      "Validation score: 0.986829\n",
      "Iteration 30, loss = 0.00272007\n",
      "Validation score: 0.992474\n",
      "Iteration 31, loss = 0.00202114\n",
      "Validation score: 0.995085\n",
      "Iteration 32, loss = 0.00147350\n",
      "Validation score: 0.995881\n",
      "Iteration 33, loss = 0.00130774\n",
      "Validation score: 0.995873\n",
      "Iteration 34, loss = 0.00122801\n",
      "Validation score: 0.995863\n",
      "Iteration 35, loss = 0.00112073\n",
      "Validation score: 0.995588\n",
      "Iteration 36, loss = 0.00106879\n",
      "Validation score: 0.996469\n",
      "Iteration 37, loss = 0.00112354\n",
      "Validation score: 0.995310\n",
      "Iteration 38, loss = 0.00142339\n",
      "Validation score: 0.995721\n",
      "Iteration 39, loss = 0.00146087\n",
      "Validation score: 0.994336\n",
      "Iteration 40, loss = 0.00139525\n",
      "Validation score: 0.993608\n",
      "Iteration 41, loss = 0.00130145\n",
      "Validation score: 0.996386\n",
      "Iteration 42, loss = 0.00123509\n",
      "Validation score: 0.995205\n",
      "Iteration 43, loss = 0.00176364\n",
      "Validation score: 0.992447\n",
      "Iteration 44, loss = 0.00262674\n",
      "Validation score: 0.991869\n",
      "Iteration 45, loss = 0.00196058\n",
      "Validation score: 0.991942\n",
      "Iteration 46, loss = 0.00258922\n",
      "Validation score: 0.994064\n",
      "Iteration 47, loss = 0.00185656\n",
      "Validation score: 0.993830\n",
      "Iteration 48, loss = 0.00191895\n",
      "Validation score: 0.995030\n",
      "Iteration 49, loss = 0.00207170\n",
      "Validation score: 0.995027\n",
      "Iteration 50, loss = 0.00142340\n",
      "Validation score: 0.996216\n",
      "Iteration 51, loss = 0.00116567\n",
      "Validation score: 0.996430\n",
      "Iteration 52, loss = 0.00116118\n",
      "Validation score: 0.996043\n",
      "Iteration 53, loss = 0.00092488\n",
      "Validation score: 0.995547\n",
      "Iteration 54, loss = 0.00196480\n",
      "Validation score: 0.995813\n",
      "Iteration 55, loss = 0.00171279\n",
      "Validation score: 0.993132\n",
      "Iteration 56, loss = 0.00227045\n",
      "Validation score: 0.995858\n",
      "Iteration 57, loss = 0.00145665\n",
      "Validation score: 0.995038\n",
      "Iteration 58, loss = 0.00105941\n",
      "Validation score: 0.996368\n",
      "Iteration 59, loss = 0.00141934\n",
      "Validation score: 0.995714\n",
      "Iteration 60, loss = 0.00130181\n",
      "Validation score: 0.996161\n",
      "Iteration 61, loss = 0.00128375\n",
      "Validation score: 0.996903\n",
      "Iteration 62, loss = 0.00108551\n",
      "Validation score: 0.995984\n",
      "Iteration 63, loss = 0.00090454\n",
      "Validation score: 0.997441\n",
      "Iteration 64, loss = 0.00084076\n",
      "Validation score: 0.997146\n",
      "Iteration 65, loss = 0.00088376\n",
      "Validation score: 0.997350\n",
      "Iteration 66, loss = 0.00085503\n",
      "Validation score: 0.993018\n",
      "Iteration 67, loss = 0.00135394\n",
      "Validation score: 0.996673\n",
      "Iteration 68, loss = 0.00120317\n",
      "Validation score: 0.996634\n",
      "Iteration 69, loss = 0.00087275\n",
      "Validation score: 0.992198\n",
      "Iteration 70, loss = 0.00188303\n",
      "Validation score: 0.992198\n",
      "Iteration 71, loss = 0.00186805\n",
      "Validation score: 0.995492\n",
      "Iteration 72, loss = 0.00131641\n",
      "Validation score: 0.995381\n",
      "Iteration 73, loss = 0.00130663\n",
      "Validation score: 0.996934\n",
      "Iteration 74, loss = 0.00105393\n",
      "Validation score: 0.993343\n",
      "Iteration 75, loss = 0.00165498\n",
      "Validation score: 0.995984\n",
      "Iteration 76, loss = 0.00105676\n",
      "Validation score: 0.995132\n",
      "Iteration 77, loss = 0.00142026\n",
      "Validation score: 0.995499\n",
      "Iteration 78, loss = 0.00115603\n",
      "Validation score: 0.996335\n",
      "Iteration 79, loss = 0.00126358\n",
      "Validation score: 0.996939\n",
      "Iteration 80, loss = 0.00140387\n",
      "Validation score: 0.995265\n",
      "Iteration 81, loss = 0.00134899\n",
      "Validation score: 0.996411\n",
      "Iteration 82, loss = 0.00096474\n",
      "Validation score: 0.996390\n",
      "Iteration 83, loss = 0.00091137\n",
      "Validation score: 0.997010\n",
      "Iteration 84, loss = 0.00094502\n",
      "Validation score: 0.997237\n",
      "Iteration 85, loss = 0.00084754\n",
      "Validation score: 0.996614\n",
      "Iteration 86, loss = 0.00119522\n",
      "Validation score: 0.996940\n",
      "Iteration 87, loss = 0.00101450\n",
      "Validation score: 0.996382\n",
      "Iteration 88, loss = 0.00094239\n",
      "Validation score: 0.995901\n",
      "Iteration 89, loss = 0.00094581\n",
      "Validation score: 0.996771\n",
      "Iteration 90, loss = 0.00095835\n",
      "Validation score: 0.997129\n",
      "Iteration 91, loss = 0.00093132\n",
      "Validation score: 0.997314\n",
      "Iteration 92, loss = 0.00111657\n",
      "Validation score: 0.994562\n",
      "Iteration 93, loss = 0.00103035\n",
      "Validation score: 0.995949\n",
      "Iteration 94, loss = 0.00132789\n",
      "Validation score: 0.994392\n",
      "Validation score did not improve more than tol=0.000100 for 30 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.29826691\n",
      "Validation score: 0.792619\n",
      "Iteration 2, loss = 0.06302068\n",
      "Validation score: 0.937869\n",
      "Iteration 3, loss = 0.02273880\n",
      "Validation score: 0.964529\n",
      "Iteration 4, loss = 0.01163839\n",
      "Validation score: 0.982121\n",
      "Iteration 5, loss = 0.00701131\n",
      "Validation score: 0.989331\n",
      "Iteration 6, loss = 0.00483120\n",
      "Validation score: 0.992945\n",
      "Iteration 7, loss = 0.00361839\n",
      "Validation score: 0.994491\n",
      "Iteration 8, loss = 0.00303025\n",
      "Validation score: 0.992470\n",
      "Iteration 9, loss = 0.00344530\n",
      "Validation score: 0.992421\n",
      "Iteration 10, loss = 0.00268360\n",
      "Validation score: 0.995755\n",
      "Iteration 11, loss = 0.00218837\n",
      "Validation score: 0.995460\n",
      "Iteration 12, loss = 0.00223483\n",
      "Validation score: 0.996603\n",
      "Iteration 13, loss = 0.00178019\n",
      "Validation score: 0.994336\n",
      "Iteration 14, loss = 0.00263595\n",
      "Validation score: 0.992939\n",
      "Iteration 15, loss = 0.00281225\n",
      "Validation score: 0.996786\n",
      "Iteration 16, loss = 0.00164806\n",
      "Validation score: 0.996454\n",
      "Iteration 17, loss = 0.00173266\n",
      "Validation score: 0.995591\n",
      "Iteration 18, loss = 0.00170156\n",
      "Validation score: 0.997386\n",
      "Iteration 19, loss = 0.00132268\n",
      "Validation score: 0.997905\n",
      "Iteration 20, loss = 0.00130378\n",
      "Validation score: 0.997887\n",
      "Iteration 21, loss = 0.00110648\n",
      "Validation score: 0.997780\n",
      "Iteration 22, loss = 0.00116211\n",
      "Validation score: 0.997201\n",
      "Iteration 23, loss = 0.00120976\n",
      "Validation score: 0.997973\n",
      "Iteration 24, loss = 0.00107620\n",
      "Validation score: 0.998339\n",
      "Iteration 25, loss = 0.00104813\n",
      "Validation score: 0.997393\n",
      "Iteration 26, loss = 0.00104429\n",
      "Validation score: 0.997597\n",
      "Iteration 27, loss = 0.00112195\n",
      "Validation score: 0.997385\n",
      "Iteration 28, loss = 0.00107462\n",
      "Validation score: 0.997909\n",
      "Iteration 29, loss = 0.00136825\n",
      "Validation score: 0.995316\n",
      "Iteration 30, loss = 0.00138950\n",
      "Validation score: 0.997853\n",
      "Iteration 31, loss = 0.00101187\n",
      "Validation score: 0.997911\n",
      "Iteration 32, loss = 0.00119138\n",
      "Validation score: 0.996791\n",
      "Iteration 33, loss = 0.00100356\n",
      "Validation score: 0.998106\n",
      "Iteration 34, loss = 0.00086787\n",
      "Validation score: 0.998753\n",
      "Iteration 35, loss = 0.00073168\n",
      "Validation score: 0.998651\n",
      "Iteration 36, loss = 0.00073597\n",
      "Validation score: 0.998632\n",
      "Iteration 37, loss = 0.00072605\n",
      "Validation score: 0.997959\n",
      "Iteration 38, loss = 0.00083725\n",
      "Validation score: 0.998623\n",
      "Iteration 39, loss = 0.00087132\n",
      "Validation score: 0.998448\n",
      "Iteration 40, loss = 0.00091100\n",
      "Validation score: 0.998365\n",
      "Iteration 41, loss = 0.00098526\n",
      "Validation score: 0.997722\n",
      "Iteration 42, loss = 0.00101268\n",
      "Validation score: 0.997564\n",
      "Iteration 43, loss = 0.00102180\n",
      "Validation score: 0.998324\n",
      "Iteration 44, loss = 0.00089952\n",
      "Validation score: 0.998703\n",
      "Iteration 45, loss = 0.00081879\n",
      "Validation score: 0.997098\n",
      "Iteration 46, loss = 0.00100196\n",
      "Validation score: 0.998794\n",
      "Iteration 47, loss = 0.00102541\n",
      "Validation score: 0.997860\n",
      "Iteration 48, loss = 0.00133156\n",
      "Validation score: 0.996642\n",
      "Iteration 49, loss = 0.00140308\n",
      "Validation score: 0.997439\n",
      "Iteration 50, loss = 0.00124602\n",
      "Validation score: 0.998502\n",
      "Iteration 51, loss = 0.00089075\n",
      "Validation score: 0.997993\n",
      "Iteration 52, loss = 0.00074206\n",
      "Validation score: 0.998729\n",
      "Iteration 53, loss = 0.00104020\n",
      "Validation score: 0.996941\n",
      "Iteration 54, loss = 0.00107771\n",
      "Validation score: 0.997679\n",
      "Iteration 55, loss = 0.00109418\n",
      "Validation score: 0.998334\n",
      "Iteration 56, loss = 0.00080241\n",
      "Validation score: 0.999057\n",
      "Iteration 57, loss = 0.00074549\n",
      "Validation score: 0.998620\n",
      "Iteration 58, loss = 0.00055628\n",
      "Validation score: 0.999034\n",
      "Iteration 59, loss = 0.00049443\n",
      "Validation score: 0.998373\n",
      "Iteration 60, loss = 0.00063797\n",
      "Validation score: 0.999171\n",
      "Iteration 61, loss = 0.00058520\n",
      "Validation score: 0.998724\n",
      "Iteration 62, loss = 0.00060885\n",
      "Validation score: 0.999214\n",
      "Iteration 63, loss = 0.00071939\n",
      "Validation score: 0.997896\n",
      "Iteration 64, loss = 0.00084994\n",
      "Validation score: 0.998599\n",
      "Iteration 65, loss = 0.00070571\n",
      "Validation score: 0.998966\n",
      "Iteration 66, loss = 0.00061928\n",
      "Validation score: 0.999116\n",
      "Iteration 67, loss = 0.00054860\n",
      "Validation score: 0.998098\n",
      "Iteration 68, loss = 0.00056690\n",
      "Validation score: 0.999140\n",
      "Iteration 69, loss = 0.00044341\n",
      "Validation score: 0.999169\n",
      "Iteration 70, loss = 0.00046404\n",
      "Validation score: 0.999155\n",
      "Iteration 71, loss = 0.00044555\n",
      "Validation score: 0.998967\n",
      "Iteration 72, loss = 0.00043631\n",
      "Validation score: 0.999093\n",
      "Iteration 73, loss = 0.00068887\n",
      "Validation score: 0.998568\n",
      "Iteration 74, loss = 0.00066360\n",
      "Validation score: 0.997830\n",
      "Iteration 75, loss = 0.00090343\n",
      "Validation score: 0.998754\n",
      "Iteration 76, loss = 0.00077682\n",
      "Validation score: 0.997751\n",
      "Iteration 77, loss = 0.00090020\n",
      "Validation score: 0.998004\n",
      "Iteration 78, loss = 0.00107805\n",
      "Validation score: 0.997064\n",
      "Iteration 79, loss = 0.00107292\n",
      "Validation score: 0.997682\n",
      "Iteration 80, loss = 0.00086792\n",
      "Validation score: 0.998493\n",
      "Iteration 81, loss = 0.00086494\n",
      "Validation score: 0.998467\n",
      "Iteration 82, loss = 0.00069709\n",
      "Validation score: 0.998578\n",
      "Iteration 83, loss = 0.00065496\n",
      "Validation score: 0.996595\n",
      "Iteration 84, loss = 0.00106386\n",
      "Validation score: 0.999081\n",
      "Iteration 85, loss = 0.00073234\n",
      "Validation score: 0.999032\n",
      "Iteration 86, loss = 0.00053058\n",
      "Validation score: 0.999011\n",
      "Iteration 87, loss = 0.00061351\n",
      "Validation score: 0.998887\n",
      "Iteration 88, loss = 0.00063229\n",
      "Validation score: 0.999028\n",
      "Iteration 89, loss = 0.00058358\n",
      "Validation score: 0.999175\n",
      "Iteration 90, loss = 0.00078828\n",
      "Validation score: 0.998138\n",
      "Iteration 91, loss = 0.00116635\n",
      "Validation score: 0.998541\n",
      "Validation score did not improve more than tol=0.000100 for 30 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.28600711\n",
      "Validation score: 0.795546\n",
      "Iteration 2, loss = 0.05954290\n",
      "Validation score: 0.935790\n",
      "Iteration 3, loss = 0.02559094\n",
      "Validation score: 0.961741\n",
      "Iteration 4, loss = 0.01577508\n",
      "Validation score: 0.977745\n",
      "Iteration 5, loss = 0.00975840\n",
      "Validation score: 0.981108\n",
      "Iteration 6, loss = 0.00833666\n",
      "Validation score: 0.986595\n",
      "Iteration 7, loss = 0.00668867\n",
      "Validation score: 0.988659\n",
      "Iteration 8, loss = 0.00558823\n",
      "Validation score: 0.982545\n",
      "Iteration 9, loss = 0.00798621\n",
      "Validation score: 0.976522\n",
      "Iteration 10, loss = 0.00830712\n",
      "Validation score: 0.984678\n",
      "Iteration 11, loss = 0.00782902\n",
      "Validation score: 0.983219\n",
      "Iteration 12, loss = 0.00724720\n",
      "Validation score: 0.983368\n",
      "Iteration 13, loss = 0.00629393\n",
      "Validation score: 0.987798\n",
      "Iteration 14, loss = 0.00593611\n",
      "Validation score: 0.991202\n",
      "Iteration 15, loss = 0.00438246\n",
      "Validation score: 0.982195\n",
      "Iteration 16, loss = 0.00766969\n",
      "Validation score: 0.990907\n",
      "Iteration 17, loss = 0.00481533\n",
      "Validation score: 0.988473\n",
      "Iteration 18, loss = 0.00459693\n",
      "Validation score: 0.990235\n",
      "Iteration 19, loss = 0.00414725\n",
      "Validation score: 0.994663\n",
      "Iteration 20, loss = 0.00285131\n",
      "Validation score: 0.995006\n",
      "Iteration 21, loss = 0.00270128\n",
      "Validation score: 0.992149\n",
      "Iteration 22, loss = 0.00424930\n",
      "Validation score: 0.991010\n",
      "Iteration 23, loss = 0.00420996\n",
      "Validation score: 0.982485\n",
      "Iteration 24, loss = 0.00591349\n",
      "Validation score: 0.989961\n",
      "Iteration 25, loss = 0.00606007\n",
      "Validation score: 0.985443\n",
      "Iteration 26, loss = 0.00384461\n",
      "Validation score: 0.993323\n",
      "Iteration 27, loss = 0.00328704\n",
      "Validation score: 0.994973\n",
      "Iteration 28, loss = 0.00253473\n",
      "Validation score: 0.992728\n",
      "Iteration 29, loss = 0.00390518\n",
      "Validation score: 0.995001\n",
      "Iteration 30, loss = 0.00280246\n",
      "Validation score: 0.994844\n",
      "Iteration 31, loss = 0.00247923\n",
      "Validation score: 0.995315\n",
      "Iteration 32, loss = 0.00274171\n",
      "Validation score: 0.989375\n",
      "Iteration 33, loss = 0.00508702\n",
      "Validation score: 0.994057\n",
      "Iteration 34, loss = 0.00407389\n",
      "Validation score: 0.994606\n",
      "Iteration 35, loss = 0.00317484\n",
      "Validation score: 0.991352\n",
      "Iteration 36, loss = 0.00406628\n",
      "Validation score: 0.994097\n",
      "Iteration 37, loss = 0.00320893\n",
      "Validation score: 0.994537\n",
      "Iteration 38, loss = 0.00393957\n",
      "Validation score: 0.989319\n",
      "Iteration 39, loss = 0.00425817\n",
      "Validation score: 0.994585\n",
      "Iteration 40, loss = 0.00256355\n",
      "Validation score: 0.991393\n",
      "Iteration 41, loss = 0.00380793\n",
      "Validation score: 0.994608\n",
      "Iteration 42, loss = 0.00208912\n",
      "Validation score: 0.996669\n",
      "Iteration 43, loss = 0.00207963\n",
      "Validation score: 0.996844\n",
      "Iteration 44, loss = 0.00231509\n",
      "Validation score: 0.996272\n",
      "Iteration 45, loss = 0.00241108\n",
      "Validation score: 0.996407\n",
      "Iteration 46, loss = 0.00206007\n",
      "Validation score: 0.996372\n",
      "Iteration 47, loss = 0.00203931\n",
      "Validation score: 0.995753\n",
      "Iteration 48, loss = 0.00290966\n",
      "Validation score: 0.996225\n",
      "Iteration 49, loss = 0.00236666\n",
      "Validation score: 0.993775\n",
      "Iteration 50, loss = 0.00350255\n",
      "Validation score: 0.992315\n",
      "Iteration 51, loss = 0.00326506\n",
      "Validation score: 0.996854\n",
      "Iteration 52, loss = 0.00204096\n",
      "Validation score: 0.996722\n",
      "Iteration 53, loss = 0.00199201\n",
      "Validation score: 0.995541\n",
      "Iteration 54, loss = 0.00165078\n",
      "Validation score: 0.997650\n",
      "Iteration 55, loss = 0.00167292\n",
      "Validation score: 0.997790\n",
      "Iteration 56, loss = 0.00177008\n",
      "Validation score: 0.991195\n",
      "Iteration 57, loss = 0.00257870\n",
      "Validation score: 0.994988\n",
      "Iteration 58, loss = 0.00200695\n",
      "Validation score: 0.998049\n",
      "Iteration 59, loss = 0.00139527\n",
      "Validation score: 0.997885\n",
      "Iteration 60, loss = 0.00128173\n",
      "Validation score: 0.997931\n",
      "Iteration 61, loss = 0.00133254\n",
      "Validation score: 0.997815\n",
      "Iteration 62, loss = 0.00142435\n",
      "Validation score: 0.998210\n",
      "Iteration 63, loss = 0.00131244\n",
      "Validation score: 0.998456\n",
      "Iteration 64, loss = 0.00131906\n",
      "Validation score: 0.997909\n",
      "Iteration 65, loss = 0.00130848\n",
      "Validation score: 0.994212\n",
      "Iteration 66, loss = 0.00325503\n",
      "Validation score: 0.991494\n",
      "Iteration 67, loss = 0.00273740\n",
      "Validation score: 0.993882\n",
      "Iteration 68, loss = 0.00209669\n",
      "Validation score: 0.997117\n",
      "Iteration 69, loss = 0.00150116\n",
      "Validation score: 0.997581\n",
      "Iteration 70, loss = 0.00128085\n",
      "Validation score: 0.997361\n",
      "Iteration 71, loss = 0.00180848\n",
      "Validation score: 0.997103\n",
      "Iteration 72, loss = 0.00173867\n",
      "Validation score: 0.996869\n",
      "Iteration 73, loss = 0.00134950\n",
      "Validation score: 0.997420\n",
      "Iteration 74, loss = 0.00153389\n",
      "Validation score: 0.998114\n",
      "Iteration 75, loss = 0.00122637\n",
      "Validation score: 0.997692\n",
      "Iteration 76, loss = 0.00160794\n",
      "Validation score: 0.997380\n",
      "Iteration 77, loss = 0.00134470\n",
      "Validation score: 0.997421\n",
      "Iteration 78, loss = 0.00134013\n",
      "Validation score: 0.994988\n",
      "Iteration 79, loss = 0.00322541\n",
      "Validation score: 0.993415\n",
      "Iteration 80, loss = 0.00214118\n",
      "Validation score: 0.993058\n",
      "Iteration 81, loss = 0.00352112\n",
      "Validation score: 0.988999\n",
      "Iteration 82, loss = 0.00373054\n",
      "Validation score: 0.989861\n",
      "Iteration 83, loss = 0.00493078\n",
      "Validation score: 0.992241\n",
      "Iteration 84, loss = 0.00333596\n",
      "Validation score: 0.989901\n",
      "Iteration 85, loss = 0.00315942\n",
      "Validation score: 0.994563\n",
      "Iteration 86, loss = 0.00364703\n",
      "Validation score: 0.992048\n",
      "Iteration 87, loss = 0.00243178\n",
      "Validation score: 0.996063\n",
      "Iteration 88, loss = 0.00196061\n",
      "Validation score: 0.996151\n",
      "Iteration 89, loss = 0.00193854\n",
      "Validation score: 0.997145\n",
      "Iteration 90, loss = 0.00168793\n",
      "Validation score: 0.994432\n",
      "Iteration 91, loss = 0.00335275\n",
      "Validation score: 0.995199\n",
      "Iteration 92, loss = 0.00329289\n",
      "Validation score: 0.996648\n",
      "Iteration 93, loss = 0.00217859\n",
      "Validation score: 0.994931\n",
      "Iteration 94, loss = 0.00255145\n",
      "Validation score: 0.991141\n",
      "Validation score did not improve more than tol=0.000100 for 30 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.29966184\n",
      "Validation score: 0.797941\n",
      "Iteration 2, loss = 0.06815375\n",
      "Validation score: 0.916834\n",
      "Iteration 3, loss = 0.03031951\n",
      "Validation score: 0.960867\n",
      "Iteration 4, loss = 0.01537799\n",
      "Validation score: 0.976293\n",
      "Iteration 5, loss = 0.00963151\n",
      "Validation score: 0.979326\n",
      "Iteration 6, loss = 0.00657667\n",
      "Validation score: 0.988555\n",
      "Iteration 7, loss = 0.00465352\n",
      "Validation score: 0.990131\n",
      "Iteration 8, loss = 0.00370026\n",
      "Validation score: 0.992267\n",
      "Iteration 9, loss = 0.00328537\n",
      "Validation score: 0.992908\n",
      "Iteration 10, loss = 0.00282285\n",
      "Validation score: 0.992993\n",
      "Iteration 11, loss = 0.00273517\n",
      "Validation score: 0.994151\n",
      "Iteration 12, loss = 0.00232551\n",
      "Validation score: 0.993643\n",
      "Iteration 13, loss = 0.00203841\n",
      "Validation score: 0.994271\n",
      "Iteration 14, loss = 0.00190779\n",
      "Validation score: 0.994106\n",
      "Iteration 15, loss = 0.00187422\n",
      "Validation score: 0.993944\n",
      "Iteration 16, loss = 0.00173448\n",
      "Validation score: 0.995195\n",
      "Iteration 17, loss = 0.00146006\n",
      "Validation score: 0.995172\n",
      "Iteration 18, loss = 0.00145543\n",
      "Validation score: 0.995023\n",
      "Iteration 19, loss = 0.00142137\n",
      "Validation score: 0.996737\n",
      "Iteration 20, loss = 0.00125989\n",
      "Validation score: 0.995890\n",
      "Iteration 21, loss = 0.00129945\n",
      "Validation score: 0.996665\n",
      "Iteration 22, loss = 0.00113275\n",
      "Validation score: 0.996209\n",
      "Iteration 23, loss = 0.00115951\n",
      "Validation score: 0.996714\n",
      "Iteration 24, loss = 0.00097573\n",
      "Validation score: 0.995859\n",
      "Iteration 25, loss = 0.00116702\n",
      "Validation score: 0.997252\n",
      "Iteration 26, loss = 0.00103999\n",
      "Validation score: 0.997276\n",
      "Iteration 27, loss = 0.00093844\n",
      "Validation score: 0.997936\n",
      "Iteration 28, loss = 0.00091963\n",
      "Validation score: 0.997522\n",
      "Iteration 29, loss = 0.00093090\n",
      "Validation score: 0.995298\n",
      "Iteration 30, loss = 0.00096214\n",
      "Validation score: 0.997386\n",
      "Iteration 31, loss = 0.00090487\n",
      "Validation score: 0.997872\n",
      "Iteration 32, loss = 0.00088057\n",
      "Validation score: 0.996006\n",
      "Iteration 33, loss = 0.00160963\n",
      "Validation score: 0.996346\n",
      "Iteration 34, loss = 0.00151204\n",
      "Validation score: 0.996628\n",
      "Iteration 35, loss = 0.00164447\n",
      "Validation score: 0.997343\n",
      "Iteration 36, loss = 0.00125106\n",
      "Validation score: 0.997457\n",
      "Iteration 37, loss = 0.00113519\n",
      "Validation score: 0.997807\n",
      "Iteration 38, loss = 0.00084301\n",
      "Validation score: 0.997068\n",
      "Iteration 39, loss = 0.00097612\n",
      "Validation score: 0.998043\n",
      "Iteration 40, loss = 0.00100680\n",
      "Validation score: 0.997387\n",
      "Iteration 41, loss = 0.00108381\n",
      "Validation score: 0.997599\n",
      "Iteration 42, loss = 0.00089647\n",
      "Validation score: 0.998175\n",
      "Iteration 43, loss = 0.00083109\n",
      "Validation score: 0.997641\n",
      "Iteration 44, loss = 0.00117167\n",
      "Validation score: 0.996809\n",
      "Iteration 45, loss = 0.00103236\n",
      "Validation score: 0.996719\n",
      "Iteration 46, loss = 0.00174249\n",
      "Validation score: 0.994827\n",
      "Iteration 47, loss = 0.00147239\n",
      "Validation score: 0.995194\n",
      "Iteration 48, loss = 0.00159734\n",
      "Validation score: 0.996425\n",
      "Iteration 49, loss = 0.00114365\n",
      "Validation score: 0.997222\n",
      "Iteration 50, loss = 0.00102841\n",
      "Validation score: 0.997930\n",
      "Iteration 51, loss = 0.00106732\n",
      "Validation score: 0.998048\n",
      "Iteration 52, loss = 0.00109753\n",
      "Validation score: 0.995457\n",
      "Iteration 53, loss = 0.00135387\n",
      "Validation score: 0.996926\n",
      "Iteration 54, loss = 0.00118825\n",
      "Validation score: 0.998129\n",
      "Iteration 55, loss = 0.00082141\n",
      "Validation score: 0.998248\n",
      "Iteration 56, loss = 0.00064772\n",
      "Validation score: 0.998206\n",
      "Iteration 57, loss = 0.00058119\n",
      "Validation score: 0.998213\n",
      "Iteration 58, loss = 0.00070123\n",
      "Validation score: 0.998459\n",
      "Iteration 59, loss = 0.00061004\n",
      "Validation score: 0.998526\n",
      "Iteration 60, loss = 0.00072721\n",
      "Validation score: 0.998036\n",
      "Iteration 61, loss = 0.00067164\n",
      "Validation score: 0.997799\n",
      "Iteration 62, loss = 0.00080395\n",
      "Validation score: 0.997914\n",
      "Iteration 63, loss = 0.00063913\n",
      "Validation score: 0.998712\n",
      "Iteration 64, loss = 0.00066783\n",
      "Validation score: 0.998323\n",
      "Iteration 65, loss = 0.00059879\n",
      "Validation score: 0.998291\n",
      "Iteration 66, loss = 0.00054991\n",
      "Validation score: 0.998769\n",
      "Iteration 67, loss = 0.00053199\n",
      "Validation score: 0.998781\n",
      "Iteration 68, loss = 0.00052500\n",
      "Validation score: 0.998611\n",
      "Iteration 69, loss = 0.00063804\n",
      "Validation score: 0.998294\n",
      "Iteration 70, loss = 0.00054517\n",
      "Validation score: 0.998519\n",
      "Iteration 71, loss = 0.00054037\n",
      "Validation score: 0.996663\n",
      "Iteration 72, loss = 0.00093305\n",
      "Validation score: 0.998270\n",
      "Iteration 73, loss = 0.00081354\n",
      "Validation score: 0.998108\n",
      "Iteration 74, loss = 0.00138290\n",
      "Validation score: 0.996574\n",
      "Iteration 75, loss = 0.00096897\n",
      "Validation score: 0.998363\n",
      "Iteration 76, loss = 0.00090223\n",
      "Validation score: 0.998171\n",
      "Iteration 77, loss = 0.00084282\n",
      "Validation score: 0.997749\n",
      "Iteration 78, loss = 0.00075307\n",
      "Validation score: 0.998035\n",
      "Iteration 79, loss = 0.00060755\n",
      "Validation score: 0.998819\n",
      "Iteration 80, loss = 0.00053323\n",
      "Validation score: 0.998146\n",
      "Iteration 81, loss = 0.00053309\n",
      "Validation score: 0.998826\n",
      "Iteration 82, loss = 0.00055194\n",
      "Validation score: 0.998782\n",
      "Iteration 83, loss = 0.00056437\n",
      "Validation score: 0.997708\n",
      "Iteration 84, loss = 0.00064230\n",
      "Validation score: 0.998698\n",
      "Iteration 85, loss = 0.00067233\n",
      "Validation score: 0.997956\n",
      "Iteration 86, loss = 0.00056401\n",
      "Validation score: 0.997395\n",
      "Iteration 87, loss = 0.00082002\n",
      "Validation score: 0.998385\n",
      "Iteration 88, loss = 0.00054574\n",
      "Validation score: 0.998534\n",
      "Iteration 89, loss = 0.00055827\n",
      "Validation score: 0.998001\n",
      "Iteration 90, loss = 0.00075558\n",
      "Validation score: 0.998200\n",
      "Iteration 91, loss = 0.00077480\n",
      "Validation score: 0.996643\n",
      "Iteration 92, loss = 0.00081060\n",
      "Validation score: 0.997730\n",
      "Iteration 93, loss = 0.00069653\n",
      "Validation score: 0.998330\n",
      "Iteration 94, loss = 0.00057886\n",
      "Validation score: 0.998956\n",
      "Iteration 95, loss = 0.00053088\n",
      "Validation score: 0.997739\n",
      "Iteration 96, loss = 0.00066003\n",
      "Validation score: 0.998728\n",
      "Iteration 97, loss = 0.00079841\n",
      "Validation score: 0.998308\n",
      "Iteration 98, loss = 0.00057799\n",
      "Validation score: 0.998409\n",
      "Iteration 99, loss = 0.00071782\n",
      "Validation score: 0.998776\n",
      "Iteration 100, loss = 0.00061475\n",
      "Validation score: 0.998473\n",
      "Iteration 101, loss = 0.00056176\n",
      "Validation score: 0.998362\n",
      "Iteration 102, loss = 0.00072455\n",
      "Validation score: 0.997681\n",
      "Iteration 103, loss = 0.00071370\n",
      "Validation score: 0.998730\n",
      "Iteration 104, loss = 0.00061989\n",
      "Validation score: 0.998660\n",
      "Iteration 105, loss = 0.00058715\n",
      "Validation score: 0.998889\n",
      "Iteration 106, loss = 0.00059169\n",
      "Validation score: 0.998212\n",
      "Iteration 107, loss = 0.00065342\n",
      "Validation score: 0.998129\n",
      "Iteration 108, loss = 0.00062287\n",
      "Validation score: 0.998792\n",
      "Iteration 109, loss = 0.00098438\n",
      "Validation score: 0.998459\n",
      "Iteration 110, loss = 0.00062376\n",
      "Validation score: 0.998417\n",
      "Iteration 111, loss = 0.00056371\n",
      "Validation score: 0.998701\n",
      "Iteration 112, loss = 0.00048268\n",
      "Validation score: 0.999136\n",
      "Iteration 113, loss = 0.00045367\n",
      "Validation score: 0.998492\n",
      "Iteration 114, loss = 0.00049574\n",
      "Validation score: 0.997898\n",
      "Iteration 115, loss = 0.00066687\n",
      "Validation score: 0.998829\n",
      "Iteration 116, loss = 0.00057243\n",
      "Validation score: 0.998927\n",
      "Iteration 117, loss = 0.00047792\n",
      "Validation score: 0.998809\n",
      "Iteration 118, loss = 0.00042287\n",
      "Validation score: 0.998541\n",
      "Iteration 119, loss = 0.00057105\n",
      "Validation score: 0.998949\n",
      "Iteration 120, loss = 0.00054685\n",
      "Validation score: 0.997917\n",
      "Iteration 121, loss = 0.00062556\n",
      "Validation score: 0.998870\n",
      "Iteration 122, loss = 0.00059121\n",
      "Validation score: 0.997181\n",
      "Iteration 123, loss = 0.00072106\n",
      "Validation score: 0.998699\n",
      "Iteration 124, loss = 0.00073664\n",
      "Validation score: 0.997979\n",
      "Iteration 125, loss = 0.00136462\n",
      "Validation score: 0.997862\n",
      "Iteration 126, loss = 0.00089081\n",
      "Validation score: 0.998389\n",
      "Iteration 127, loss = 0.00083111\n",
      "Validation score: 0.998117\n",
      "Iteration 128, loss = 0.00068204\n",
      "Validation score: 0.998346\n",
      "Iteration 129, loss = 0.00081461\n",
      "Validation score: 0.998001\n",
      "Iteration 130, loss = 0.00093878\n",
      "Validation score: 0.997763\n",
      "Iteration 131, loss = 0.00112042\n",
      "Validation score: 0.995622\n",
      "Iteration 132, loss = 0.00081976\n",
      "Validation score: 0.998633\n",
      "Iteration 133, loss = 0.00054559\n",
      "Validation score: 0.998785\n",
      "Iteration 134, loss = 0.00052483\n",
      "Validation score: 0.998471\n",
      "Iteration 135, loss = 0.00044637\n",
      "Validation score: 0.999327\n",
      "Iteration 136, loss = 0.00049205\n",
      "Validation score: 0.998980\n",
      "Iteration 137, loss = 0.00055377\n",
      "Validation score: 0.999022\n",
      "Iteration 138, loss = 0.00052254\n",
      "Validation score: 0.998553\n",
      "Iteration 139, loss = 0.00059215\n",
      "Validation score: 0.998926\n",
      "Iteration 140, loss = 0.00045826\n",
      "Validation score: 0.998756\n",
      "Iteration 141, loss = 0.00078424\n",
      "Validation score: 0.998646\n",
      "Iteration 142, loss = 0.00063089\n",
      "Validation score: 0.998735\n",
      "Iteration 143, loss = 0.00062728\n",
      "Validation score: 0.998787\n",
      "Iteration 144, loss = 0.00051582\n",
      "Validation score: 0.998309\n",
      "Iteration 145, loss = 0.00054121\n",
      "Validation score: 0.998763\n",
      "Iteration 146, loss = 0.00053277\n",
      "Validation score: 0.998667\n",
      "Iteration 147, loss = 0.00047458\n",
      "Validation score: 0.999325\n",
      "Iteration 148, loss = 0.00043410\n",
      "Validation score: 0.998467\n",
      "Iteration 149, loss = 0.00050578\n",
      "Validation score: 0.998562\n",
      "Iteration 150, loss = 0.00059432\n",
      "Validation score: 0.998369\n",
      "Iteration 151, loss = 0.00068471\n",
      "Validation score: 0.998058\n",
      "Iteration 152, loss = 0.00062108\n",
      "Validation score: 0.998608\n",
      "Iteration 153, loss = 0.00057987\n",
      "Validation score: 0.998746\n",
      "Iteration 154, loss = 0.00056578\n",
      "Validation score: 0.999181\n",
      "Iteration 155, loss = 0.00060169\n",
      "Validation score: 0.998766\n",
      "Iteration 156, loss = 0.00062226\n",
      "Validation score: 0.998130\n",
      "Iteration 157, loss = 0.00059396\n",
      "Validation score: 0.998619\n",
      "Iteration 158, loss = 0.00062720\n",
      "Validation score: 0.998706\n",
      "Iteration 159, loss = 0.00048839\n",
      "Validation score: 0.999334\n",
      "Iteration 160, loss = 0.00058474\n",
      "Validation score: 0.998136\n",
      "Iteration 161, loss = 0.00046012\n",
      "Validation score: 0.999257\n",
      "Iteration 162, loss = 0.00042344\n",
      "Validation score: 0.999123\n",
      "Iteration 163, loss = 0.00036539\n",
      "Validation score: 0.999315\n",
      "Iteration 164, loss = 0.00034660\n",
      "Validation score: 0.999286\n",
      "Iteration 165, loss = 0.00040507\n",
      "Validation score: 0.998754\n",
      "Iteration 166, loss = 0.00039444\n",
      "Validation score: 0.999187\n",
      "Validation score did not improve more than tol=0.000100 for 30 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.20006190\n",
      "Validation score: 0.912847\n",
      "Iteration 2, loss = 0.02510077\n",
      "Validation score: 0.973271\n",
      "Iteration 3, loss = 0.00966405\n",
      "Validation score: 0.987518\n",
      "Iteration 4, loss = 0.00549330\n",
      "Validation score: 0.992245\n",
      "Iteration 5, loss = 0.00342437\n",
      "Validation score: 0.994705\n",
      "Iteration 6, loss = 0.00257696\n",
      "Validation score: 0.996004\n",
      "Iteration 7, loss = 0.00212337\n",
      "Validation score: 0.996832\n",
      "Iteration 8, loss = 0.00171319\n",
      "Validation score: 0.997605\n",
      "Iteration 9, loss = 0.00161808\n",
      "Validation score: 0.997189\n",
      "Iteration 10, loss = 0.00139776\n",
      "Validation score: 0.998308\n",
      "Iteration 11, loss = 0.00124441\n",
      "Validation score: 0.997884\n",
      "Iteration 12, loss = 0.00113358\n",
      "Validation score: 0.998331\n",
      "Iteration 13, loss = 0.00118317\n",
      "Validation score: 0.998575\n",
      "Iteration 14, loss = 0.00109267\n",
      "Validation score: 0.998766\n",
      "Iteration 15, loss = 0.00090690\n",
      "Validation score: 0.998862\n",
      "Iteration 16, loss = 0.00084036\n",
      "Validation score: 0.999001\n",
      "Iteration 17, loss = 0.00073742\n",
      "Validation score: 0.998987\n",
      "Iteration 18, loss = 0.00068175\n",
      "Validation score: 0.999032\n",
      "Iteration 19, loss = 0.00070808\n",
      "Validation score: 0.998854\n",
      "Iteration 20, loss = 0.00066044\n",
      "Validation score: 0.999238\n",
      "Iteration 21, loss = 0.00058319\n",
      "Validation score: 0.999293\n",
      "Iteration 22, loss = 0.00052947\n",
      "Validation score: 0.999217\n",
      "Iteration 23, loss = 0.00052740\n",
      "Validation score: 0.999330\n",
      "Iteration 24, loss = 0.00054600\n",
      "Validation score: 0.999271\n",
      "Iteration 25, loss = 0.00053737\n",
      "Validation score: 0.999408\n",
      "Iteration 26, loss = 0.00054523\n",
      "Validation score: 0.998906\n",
      "Iteration 27, loss = 0.00063781\n",
      "Validation score: 0.999384\n",
      "Iteration 28, loss = 0.00060242\n",
      "Validation score: 0.998939\n",
      "Iteration 29, loss = 0.00059555\n",
      "Validation score: 0.999181\n",
      "Iteration 30, loss = 0.00061091\n",
      "Validation score: 0.999343\n",
      "Iteration 31, loss = 0.00048040\n",
      "Validation score: 0.999393\n",
      "Iteration 32, loss = 0.00046063\n",
      "Validation score: 0.999068\n",
      "Iteration 33, loss = 0.00054576\n",
      "Validation score: 0.999271\n",
      "Iteration 34, loss = 0.00057705\n",
      "Validation score: 0.999401\n",
      "Iteration 35, loss = 0.00050933\n",
      "Validation score: 0.998836\n",
      "Iteration 36, loss = 0.00057961\n",
      "Validation score: 0.999307\n",
      "Iteration 37, loss = 0.00047056\n",
      "Validation score: 0.999519\n",
      "Iteration 38, loss = 0.00049951\n",
      "Validation score: 0.999568\n",
      "Iteration 39, loss = 0.00044233\n",
      "Validation score: 0.999520\n",
      "Iteration 40, loss = 0.00048565\n",
      "Validation score: 0.999582\n",
      "Iteration 41, loss = 0.00049899\n",
      "Validation score: 0.999363\n",
      "Iteration 42, loss = 0.00059794\n",
      "Validation score: 0.999177\n",
      "Iteration 43, loss = 0.00054318\n",
      "Validation score: 0.999239\n",
      "Iteration 44, loss = 0.00053747\n",
      "Validation score: 0.999494\n",
      "Iteration 45, loss = 0.00048758\n",
      "Validation score: 0.999202\n",
      "Iteration 46, loss = 0.00051143\n",
      "Validation score: 0.999326\n",
      "Iteration 47, loss = 0.00066476\n",
      "Validation score: 0.998898\n",
      "Iteration 48, loss = 0.00072185\n",
      "Validation score: 0.999350\n",
      "Iteration 49, loss = 0.00049661\n",
      "Validation score: 0.999551\n",
      "Iteration 50, loss = 0.00038903\n",
      "Validation score: 0.999600\n",
      "Iteration 51, loss = 0.00035049\n",
      "Validation score: 0.999687\n",
      "Iteration 52, loss = 0.00037432\n",
      "Validation score: 0.999508\n",
      "Iteration 53, loss = 0.00042404\n",
      "Validation score: 0.999564\n",
      "Iteration 54, loss = 0.00038645\n",
      "Validation score: 0.999612\n",
      "Iteration 55, loss = 0.00036327\n",
      "Validation score: 0.999582\n",
      "Iteration 56, loss = 0.00034388\n",
      "Validation score: 0.999728\n",
      "Iteration 57, loss = 0.00032955\n",
      "Validation score: 0.999651\n",
      "Iteration 58, loss = 0.00033761\n",
      "Validation score: 0.999701\n",
      "Iteration 59, loss = 0.00033415\n",
      "Validation score: 0.999658\n",
      "Iteration 60, loss = 0.00033027\n",
      "Validation score: 0.999373\n",
      "Iteration 61, loss = 0.00039150\n",
      "Validation score: 0.999389\n",
      "Iteration 62, loss = 0.00038776\n",
      "Validation score: 0.999683\n",
      "Iteration 63, loss = 0.00039082\n",
      "Validation score: 0.999665\n",
      "Iteration 64, loss = 0.00033807\n",
      "Validation score: 0.999679\n",
      "Iteration 65, loss = 0.00037399\n",
      "Validation score: 0.999545\n",
      "Iteration 66, loss = 0.00036668\n",
      "Validation score: 0.999790\n",
      "Iteration 67, loss = 0.00035329\n",
      "Validation score: 0.999683\n",
      "Iteration 68, loss = 0.00032864\n",
      "Validation score: 0.999699\n",
      "Validation score did not improve more than tol=0.000100 for 30 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "mlps.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.286007108031892,\n",
       " 0.05954290176788805,\n",
       " 0.025590942766196816,\n",
       " 0.01577508140277233,\n",
       " 0.009758402511503677,\n",
       " 0.008336662219956053,\n",
       " 0.006688672800187371,\n",
       " 0.005588225170220068,\n",
       " 0.007986207769388276,\n",
       " 0.00830711775584576,\n",
       " 0.007829018125023833,\n",
       " 0.007247199318948999,\n",
       " 0.006293930337606957,\n",
       " 0.005936106874366884,\n",
       " 0.004382457639453905,\n",
       " 0.007669686393263391,\n",
       " 0.004815333815175849,\n",
       " 0.00459693157245642,\n",
       " 0.0041472474255578925,\n",
       " 0.00285131072393476,\n",
       " 0.0027012772793908665,\n",
       " 0.004249298349894794,\n",
       " 0.004209961058903157,\n",
       " 0.005913494563230873,\n",
       " 0.006060069479254591,\n",
       " 0.0038446095954276093,\n",
       " 0.0032870362919604295,\n",
       " 0.0025347303993796754,\n",
       " 0.0039051807576236906,\n",
       " 0.0028024629940645754,\n",
       " 0.0024792305532721245,\n",
       " 0.002741713752525464,\n",
       " 0.005087019645981756,\n",
       " 0.004073894948992518,\n",
       " 0.0031748437442056876,\n",
       " 0.004066278030731815,\n",
       " 0.0032089323382548424,\n",
       " 0.003939570207751972,\n",
       " 0.004258170349601642,\n",
       " 0.002563547670691551,\n",
       " 0.003807934880784459,\n",
       " 0.0020891167100172913,\n",
       " 0.0020796273165652472,\n",
       " 0.0023150866735748587,\n",
       " 0.0024110840060836206,\n",
       " 0.002060067633673795,\n",
       " 0.002039306186721189,\n",
       " 0.0029096635904766978,\n",
       " 0.0023666631337892494,\n",
       " 0.003502554745111969,\n",
       " 0.0032650648474001403,\n",
       " 0.0020409558720712955,\n",
       " 0.0019920071126412133,\n",
       " 0.0016507800068130607,\n",
       " 0.0016729234000184804,\n",
       " 0.0017700776916211012,\n",
       " 0.002578696090197458,\n",
       " 0.002006952291538029,\n",
       " 0.0013952739097674353,\n",
       " 0.0012817273396667237,\n",
       " 0.0013325366869167874,\n",
       " 0.0014243481216479764,\n",
       " 0.0013124416045146893,\n",
       " 0.0013190588723277572,\n",
       " 0.0013084806227525744,\n",
       " 0.0032550281322529366,\n",
       " 0.002737404627169328,\n",
       " 0.0020966881201152205,\n",
       " 0.0015011559860840262,\n",
       " 0.0012808494119976067,\n",
       " 0.0018084810718378222,\n",
       " 0.0017386665285833746,\n",
       " 0.0013494981978734168,\n",
       " 0.0015338886346609477,\n",
       " 0.0012263712700493169,\n",
       " 0.0016079369815892777,\n",
       " 0.0013447049067211471,\n",
       " 0.001340134025870617,\n",
       " 0.0032254075016346423,\n",
       " 0.0021411781097528467,\n",
       " 0.003521124629038595,\n",
       " 0.0037305395248776367,\n",
       " 0.004930784859034128,\n",
       " 0.003335956270812795,\n",
       " 0.0031594216642436774,\n",
       " 0.0036470272874550226,\n",
       " 0.0024317802620559986,\n",
       " 0.0019606062700237748,\n",
       " 0.0019385388243995671,\n",
       " 0.0016879263448196706,\n",
       " 0.003352750408726807,\n",
       " 0.003292893706657376,\n",
       " 0.002178591230965224,\n",
       " 0.002551448792161125]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "loss = mlps._models[3]._model.loss_curve_\n",
    "\n",
    "plt.plot(range(1,len(loss)+1), loss, color='black')\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinematicsrobotics.kinematics import Robo\n",
    "from kinematicsrobotics.metrics import Metrics\n",
    "Elos = [['theta_1',10,0,90,0],\n",
    "        ['theta_2',0,18,180,0],\n",
    "        ['theta_3',0,18,-180,0],\n",
    "        ['theta_4',0,0,90,90],\n",
    "        ['theta_5',18,0,0,0]\n",
    "]\n",
    "\n",
    "robo = Robo(\"Robo\", Elos)\n",
    "\n",
    "\n",
    "metric = Metrics(model = mlps._models[0],\n",
    "                 scaler_x = mlps._data_processing[0]._scaler_x , \n",
    "                 scaler_y = mlps._data_processing[0]._scaler_y,\n",
    "                 robo=robo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = mlps._data_processing[0].data_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58137205, 1.13913517, 4.24379963, 1.47145718])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.mse_joint(x = x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06835117, 0.03737069, 0.03558842])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.mse_operacional(x=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55310491, 0.768259  , 3.17648931, 1.35460025])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.mse_joint(x = x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06110464, 0.03506326, 0.03578217])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.mse_operacional(x=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1881517 , 0.44424366, 1.43616094, 0.61525906])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = Metrics(model = mlps._models[2],\n",
    "                 scaler_x = mlps._data_processing[2]._scaler_x , \n",
    "                 scaler_y = mlps._data_processing[2]._scaler_y,\n",
    "                 robo=robo)\n",
    "\n",
    "x_train, x_test, y_train, y_test = mlps._data_processing[2].data_train_test\n",
    "metric.mse_joint(x = x_train, y=y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
