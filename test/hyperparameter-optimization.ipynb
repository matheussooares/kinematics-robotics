{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.abspath(Path().resolve().parent/'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cinemática Inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinematicsrobotics.datahandler import Save, Extract\n",
    "from kinematicsrobotics.dataprocessing import Preprocessing\n",
    "from kinematicsrobotics.model import Model\n",
    "from kinematicsrobotics.metrics import Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta_1</th>\n",
       "      <th>theta_2</th>\n",
       "      <th>theta_3</th>\n",
       "      <th>theta_4</th>\n",
       "      <th>theta_5</th>\n",
       "      <th>p_x</th>\n",
       "      <th>p_y</th>\n",
       "      <th>p_z</th>\n",
       "      <th>roll</th>\n",
       "      <th>pich</th>\n",
       "      <th>yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.213314</td>\n",
       "      <td>-2.477121e-15</td>\n",
       "      <td>2.515179</td>\n",
       "      <td>3.141593e+00</td>\n",
       "      <td>-1.361357</td>\n",
       "      <td>2.752040e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.606657</td>\n",
       "      <td>-1.789652e-15</td>\n",
       "      <td>13.742410</td>\n",
       "      <td>2.378531e+00</td>\n",
       "      <td>-1.570796</td>\n",
       "      <td>7.630613e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.819970</td>\n",
       "      <td>-3.124530e-15</td>\n",
       "      <td>6.257590</td>\n",
       "      <td>3.141593e+00</td>\n",
       "      <td>-1.361357</td>\n",
       "      <td>2.371518e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>53.213314</td>\n",
       "      <td>-2.915404e-15</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.356194e+00</td>\n",
       "      <td>-1.570796</td>\n",
       "      <td>7.853982e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>51.657132</td>\n",
       "      <td>-4.201082e-15</td>\n",
       "      <td>2.678740</td>\n",
       "      <td>3.141593e+00</td>\n",
       "      <td>-1.361357</td>\n",
       "      <td>2.500234e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6884</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>1.558846e+01</td>\n",
       "      <td>41.176915</td>\n",
       "      <td>-2.026424e-16</td>\n",
       "      <td>-0.523599</td>\n",
       "      <td>-1.047198e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6885</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.281153</td>\n",
       "      <td>1.261133e+01</td>\n",
       "      <td>42.707475</td>\n",
       "      <td>-1.899993e-16</td>\n",
       "      <td>-0.314159</td>\n",
       "      <td>-1.047198e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6886</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.440756</td>\n",
       "      <td>9.423666e+00</td>\n",
       "      <td>43.489851</td>\n",
       "      <td>-1.843716e-16</td>\n",
       "      <td>-0.104720</td>\n",
       "      <td>-1.047198e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6887</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.559244</td>\n",
       "      <td>6.164791e+00</td>\n",
       "      <td>43.489851</td>\n",
       "      <td>-1.843716e-16</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>-1.047198e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6888</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.718847</td>\n",
       "      <td>2.977130e+00</td>\n",
       "      <td>42.707475</td>\n",
       "      <td>-1.899993e-16</td>\n",
       "      <td>0.314159</td>\n",
       "      <td>-1.047198e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6889 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      theta_1  theta_2  theta_3  theta_4  theta_5        p_x           p_y  \\\n",
       "0           0        0       12        0        0  53.213314 -2.477121e-15   \n",
       "1           0       12       12        0        0  53.606657 -1.789652e-15   \n",
       "2           0       12       24        0        0  52.819970 -3.124530e-15   \n",
       "3           0       12       24       12        0  53.213314 -2.915404e-15   \n",
       "4           0       12       36       12        0  51.657132 -4.201082e-15   \n",
       "...       ...      ...      ...      ...      ...        ...           ...   \n",
       "6884      120      120      120       60        0  -9.000000  1.558846e+01   \n",
       "6885      120      120      120       72        0  -7.281153  1.261133e+01   \n",
       "6886      120      120      120       84        0  -5.440756  9.423666e+00   \n",
       "6887      120      120      120       96        0  -3.559244  6.164791e+00   \n",
       "6888      120      120      120      108        0  -1.718847  2.977130e+00   \n",
       "\n",
       "            p_z          roll      pich           yaw  \n",
       "0      2.515179  3.141593e+00 -1.361357  2.752040e-16  \n",
       "1     13.742410  2.378531e+00 -1.570796  7.630613e-01  \n",
       "2      6.257590  3.141593e+00 -1.361357  2.371518e-16  \n",
       "3     10.000000  2.356194e+00 -1.570796  7.853982e-01  \n",
       "4      2.678740  3.141593e+00 -1.361357  2.500234e-16  \n",
       "...         ...           ...       ...           ...  \n",
       "6884  41.176915 -2.026424e-16 -0.523599 -1.047198e+00  \n",
       "6885  42.707475 -1.899993e-16 -0.314159 -1.047198e+00  \n",
       "6886  43.489851 -1.843716e-16 -0.104720 -1.047198e+00  \n",
       "6887  43.489851 -1.843716e-16  0.104720 -1.047198e+00  \n",
       "6888  42.707475 -1.899993e-16  0.314159 -1.047198e+00  \n",
       "\n",
       "[6889 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext = Extract()\n",
    "ext._path_project = os.path.abspath(Path().resolve().parent)\n",
    "\n",
    "dataset = ext.dataframe(r'src\\data\\ready\\dataset-radius-1cm.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_train,size_val,size_test = 0.7, 0.2, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = Preprocessing(dataset = dataset, \n",
    "                           x_labels=['p_x', 'p_y','p_z', 'roll', 'pich', 'yaw'],\n",
    "                           y_labels=['theta_1', 'theta_2', 'theta_3', 'theta_4']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = data.data_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(early_stopping=True, max_iter=1000, n_iter_no_change=5,\n",
       "             random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, max_iter=1000, n_iter_no_change=5,\n",
       "             random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(early_stopping=True, max_iter=1000, n_iter_no_change=5,\n",
       "             random_state=42, verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = Model.mlp_regressor()\n",
    "mlp.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimação dos hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, RandomizedSearchCV, GridSearchCV\n",
    "from kinematicsrobotics.datahandler import Save\n",
    "from pandas import DataFrame\n",
    "from itertools import product\n",
    "\n",
    "class ParameterOptimizer:\n",
    "    \n",
    "    def __init__(self, *, model: Model, x_train, y_train, size_train = 0.7, size_val =  0.1, size_test = 0.2, n_splits: int = 4) -> None:\n",
    "        self._save = Save()\n",
    "        self._model = model\n",
    "        self._x = x_train\n",
    "        self._y = y_train\n",
    "        self.size_validation(size_train = size_train, \n",
    "                             size_val = size_val,\n",
    "                             size_test = size_test\n",
    "        )\n",
    "        self.holdout(n_splits = n_splits)\n",
    "    \n",
    "    # Método público que define a divisão dos dados de treino e validação\n",
    "    def size_validation(self, *, size_train, size_val, size_test):\n",
    "        self._size_val = (1 - size_train/(size_train+size_val))\n",
    "        self._size_train = 1 - self._size_val\n",
    "        self._size_test = size_test\n",
    "\n",
    "    # Validação cruzada hold out\n",
    "    def holdout(self, *, n_splits = 4):\n",
    "        self._n_splits = n_splits\n",
    "        \n",
    "        self._cv = ShuffleSplit(n_splits=n_splits, \n",
    "                                test_size = self._size_val, \n",
    "                                random_state=42\n",
    "        )\n",
    "    \n",
    "       \n",
    "class ParameterSearchMLP(ParameterOptimizer):\n",
    "    def __init__(self, *, min_neurons: int, max_neurons: int, num_layers: int, step: int, **kw) -> None:\n",
    "        self._min_neurons = min_neurons\n",
    "        self._max_neurons = max_neurons\n",
    "        self._num_layers = num_layers\n",
    "        self._step = step\n",
    "        super().__init__(**kw)\n",
    "\n",
    "    def RandomizedSearch(self,*, scoring = 'neg_mean_squared_error', n_iter, path_cv_results = None, path_best_params = None):\n",
    "        # Configura os parâmetros da técnica de otimização \n",
    "        random_search = RandomizedSearchCV(estimator = self._model.model, \n",
    "                                           param_distributions = self.param_grid, \n",
    "                                           scoring = scoring, \n",
    "                                           cv = self._cv, \n",
    "                                           n_iter = n_iter, \n",
    "                                           random_state = 42, \n",
    "                                           return_train_score = True,\n",
    "                                           verbose = True\n",
    "        )\n",
    "        \n",
    "        # Treina os modelos\n",
    "        random_search.fit(self._x, self._y)\n",
    "\n",
    "        # DataFrame que armazena os resultado dos hiperparâmetros\n",
    "        history = DataFrame(random_search.cv_results_)\n",
    "\n",
    "        best_params = DataFrame(random_search.best_params_)\n",
    "\n",
    "        if path_cv_results:\n",
    "            self._save.dataframe(data = history, path_data = path_cv_results)\n",
    "        \n",
    "        if path_best_params:\n",
    "            self._save.dataframe(data = best_params, path_data = path_best_params)\n",
    "\n",
    "        # Melhor hiperparâmetro\n",
    "        \n",
    "       \n",
    "\n",
    "        return random_search.best_estimator_\n",
    "    \n",
    "    def parameter(self, *, activation):\n",
    "        param_grid = []\n",
    "        \n",
    "        for i, layers in enumerate(self._num_layers):\n",
    "            hidden_layer = self.space_hidden(layers = layers, \n",
    "                                             min_neurons = self._min_neurons[i], \n",
    "                                             max_neurons = self._max_neurons[i], \n",
    "                                             step = self._step[i]\n",
    "            )\n",
    "\n",
    "            param = { \n",
    "                'hidden_layer_sizes': hidden_layer,\n",
    "                'activation': activation\n",
    "            }\n",
    "            param_grid.append(param)\n",
    " \n",
    "        self.param_grid = param_grid\n",
    "            \n",
    "\n",
    "    def space_hidden(self,*, layers, min_neurons, max_neurons, step):    \n",
    "        # Gera a lista de possíveis números de neurônios em cada camada\n",
    "        possible_neurons = list(range(min_neurons, max_neurons + 1, step))\n",
    "\n",
    "        return list(product(possible_neurons, repeat=layers))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Iteration 1, loss = 0.28446713\n",
      "Validation score: 0.506161\n",
      "Iteration 2, loss = 0.23685149\n",
      "Validation score: 0.525045\n",
      "Iteration 3, loss = 0.23352918\n",
      "Validation score: 0.530769\n",
      "Iteration 4, loss = 0.23191838\n",
      "Validation score: 0.523460\n",
      "Iteration 5, loss = 0.23219462\n",
      "Validation score: 0.525832\n",
      "Iteration 6, loss = 0.23335716\n",
      "Validation score: 0.527574\n",
      "Iteration 7, loss = 0.23248570\n",
      "Validation score: 0.528995\n",
      "Iteration 8, loss = 0.23219028\n",
      "Validation score: 0.528386\n",
      "Iteration 9, loss = 0.23222707\n",
      "Validation score: 0.529000\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.28302664\n",
      "Validation score: 0.521843\n",
      "Iteration 2, loss = 0.23685831\n",
      "Validation score: 0.534054\n",
      "Iteration 3, loss = 0.23409416\n",
      "Validation score: 0.533197\n",
      "Iteration 4, loss = 0.23380688\n",
      "Validation score: 0.538896\n",
      "Iteration 5, loss = 0.23408157\n",
      "Validation score: 0.534215\n",
      "Iteration 6, loss = 0.23402959\n",
      "Validation score: 0.532598\n",
      "Iteration 7, loss = 0.23315615\n",
      "Validation score: 0.535700\n",
      "Iteration 8, loss = 0.23289305\n",
      "Validation score: 0.532515\n",
      "Iteration 9, loss = 0.23302119\n",
      "Validation score: 0.535085\n",
      "Iteration 10, loss = 0.23383046\n",
      "Validation score: 0.538000\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.27922721\n",
      "Validation score: 0.528119\n",
      "Iteration 2, loss = 0.23550037\n",
      "Validation score: 0.539400\n",
      "Iteration 3, loss = 0.23333063\n",
      "Validation score: 0.534593\n",
      "Iteration 4, loss = 0.23412615\n",
      "Validation score: 0.532726\n",
      "Iteration 5, loss = 0.23353549\n",
      "Validation score: 0.537063\n",
      "Iteration 6, loss = 0.23451851\n",
      "Validation score: 0.536210\n",
      "Iteration 7, loss = 0.23360858\n",
      "Validation score: 0.541265\n",
      "Iteration 8, loss = 0.23374712\n",
      "Validation score: 0.536159\n",
      "Iteration 9, loss = 0.23276727\n",
      "Validation score: 0.539064\n",
      "Iteration 10, loss = 0.23269594\n",
      "Validation score: 0.542698\n",
      "Iteration 11, loss = 0.23201888\n",
      "Validation score: 0.543437\n",
      "Iteration 12, loss = 0.23285506\n",
      "Validation score: 0.538798\n",
      "Iteration 13, loss = 0.23181261\n",
      "Validation score: 0.541053\n",
      "Iteration 14, loss = 0.23021496\n",
      "Validation score: 0.544700\n",
      "Iteration 15, loss = 0.22986136\n",
      "Validation score: 0.547154\n",
      "Iteration 16, loss = 0.22859915\n",
      "Validation score: 0.550306\n",
      "Iteration 17, loss = 0.22586461\n",
      "Validation score: 0.551417\n",
      "Iteration 18, loss = 0.22366467\n",
      "Validation score: 0.560960\n",
      "Iteration 19, loss = 0.21830325\n",
      "Validation score: 0.570010\n",
      "Iteration 20, loss = 0.21503811\n",
      "Validation score: 0.577481\n",
      "Iteration 21, loss = 0.20844990\n",
      "Validation score: 0.589710\n",
      "Iteration 22, loss = 0.20137956\n",
      "Validation score: 0.607967\n",
      "Iteration 23, loss = 0.19259932\n",
      "Validation score: 0.626295\n",
      "Iteration 24, loss = 0.18379958\n",
      "Validation score: 0.643808\n",
      "Iteration 25, loss = 0.17519835\n",
      "Validation score: 0.658455\n",
      "Iteration 26, loss = 0.16492976\n",
      "Validation score: 0.682841\n",
      "Iteration 27, loss = 0.15465998\n",
      "Validation score: 0.699405\n",
      "Iteration 28, loss = 0.14478551\n",
      "Validation score: 0.718142\n",
      "Iteration 29, loss = 0.13567011\n",
      "Validation score: 0.732421\n",
      "Iteration 30, loss = 0.12878914\n",
      "Validation score: 0.740485\n",
      "Iteration 31, loss = 0.12379777\n",
      "Validation score: 0.749976\n",
      "Iteration 32, loss = 0.11850927\n",
      "Validation score: 0.762408\n",
      "Iteration 33, loss = 0.11420011\n",
      "Validation score: 0.767122\n",
      "Iteration 34, loss = 0.11061880\n",
      "Validation score: 0.777290\n",
      "Iteration 35, loss = 0.10658494\n",
      "Validation score: 0.785430\n",
      "Iteration 36, loss = 0.10179787\n",
      "Validation score: 0.794250\n",
      "Iteration 37, loss = 0.09775304\n",
      "Validation score: 0.801273\n",
      "Iteration 38, loss = 0.09433012\n",
      "Validation score: 0.809019\n",
      "Iteration 39, loss = 0.08980844\n",
      "Validation score: 0.818697\n",
      "Iteration 40, loss = 0.08572223\n",
      "Validation score: 0.822773\n",
      "Iteration 41, loss = 0.08263012\n",
      "Validation score: 0.828183\n",
      "Iteration 42, loss = 0.07942906\n",
      "Validation score: 0.836244\n",
      "Iteration 43, loss = 0.07634583\n",
      "Validation score: 0.843648\n",
      "Iteration 44, loss = 0.07398871\n",
      "Validation score: 0.850796\n",
      "Iteration 45, loss = 0.07168495\n",
      "Validation score: 0.855386\n",
      "Iteration 46, loss = 0.07031250\n",
      "Validation score: 0.855787\n",
      "Iteration 47, loss = 0.06815010\n",
      "Validation score: 0.863819\n",
      "Iteration 48, loss = 0.06593718\n",
      "Validation score: 0.865169\n",
      "Iteration 49, loss = 0.06481010\n",
      "Validation score: 0.871254\n",
      "Iteration 50, loss = 0.06255787\n",
      "Validation score: 0.873353\n",
      "Iteration 51, loss = 0.06093341\n",
      "Validation score: 0.879278\n",
      "Iteration 52, loss = 0.05926036\n",
      "Validation score: 0.878987\n",
      "Iteration 53, loss = 0.05758820\n",
      "Validation score: 0.882485\n",
      "Iteration 54, loss = 0.05585249\n",
      "Validation score: 0.884043\n",
      "Iteration 55, loss = 0.05528401\n",
      "Validation score: 0.889035\n",
      "Iteration 56, loss = 0.05379786\n",
      "Validation score: 0.891887\n",
      "Iteration 57, loss = 0.05205192\n",
      "Validation score: 0.892921\n",
      "Iteration 58, loss = 0.05157044\n",
      "Validation score: 0.894994\n",
      "Iteration 59, loss = 0.05003405\n",
      "Validation score: 0.897868\n",
      "Iteration 60, loss = 0.04857211\n",
      "Validation score: 0.899626\n",
      "Iteration 61, loss = 0.04766406\n",
      "Validation score: 0.904144\n",
      "Iteration 62, loss = 0.04675398\n",
      "Validation score: 0.904565\n",
      "Iteration 63, loss = 0.04583162\n",
      "Validation score: 0.907546\n",
      "Iteration 64, loss = 0.04487659\n",
      "Validation score: 0.907270\n",
      "Iteration 65, loss = 0.04436666\n",
      "Validation score: 0.909774\n",
      "Iteration 66, loss = 0.04297029\n",
      "Validation score: 0.913555\n",
      "Iteration 67, loss = 0.04258340\n",
      "Validation score: 0.914351\n",
      "Iteration 68, loss = 0.04167858\n",
      "Validation score: 0.916426\n",
      "Iteration 69, loss = 0.04073815\n",
      "Validation score: 0.914004\n",
      "Iteration 70, loss = 0.04049649\n",
      "Validation score: 0.918246\n",
      "Iteration 71, loss = 0.03960400\n",
      "Validation score: 0.920650\n",
      "Iteration 72, loss = 0.03888542\n",
      "Validation score: 0.919594\n",
      "Iteration 73, loss = 0.03804744\n",
      "Validation score: 0.922729\n",
      "Iteration 74, loss = 0.03736103\n",
      "Validation score: 0.924511\n",
      "Iteration 75, loss = 0.03708567\n",
      "Validation score: 0.923626\n",
      "Iteration 76, loss = 0.03658584\n",
      "Validation score: 0.927391\n",
      "Iteration 77, loss = 0.03604451\n",
      "Validation score: 0.928416\n",
      "Iteration 78, loss = 0.03544191\n",
      "Validation score: 0.928811\n",
      "Iteration 79, loss = 0.03473833\n",
      "Validation score: 0.929257\n",
      "Iteration 80, loss = 0.03402337\n",
      "Validation score: 0.931742\n",
      "Iteration 81, loss = 0.03361576\n",
      "Validation score: 0.930291\n",
      "Iteration 82, loss = 0.03333766\n",
      "Validation score: 0.933187\n",
      "Iteration 83, loss = 0.03263241\n",
      "Validation score: 0.933376\n",
      "Iteration 84, loss = 0.03220599\n",
      "Validation score: 0.935704\n",
      "Iteration 85, loss = 0.03216675\n",
      "Validation score: 0.935501\n",
      "Iteration 86, loss = 0.03170179\n",
      "Validation score: 0.935965\n",
      "Iteration 87, loss = 0.03111750\n",
      "Validation score: 0.936882\n",
      "Iteration 88, loss = 0.03045894\n",
      "Validation score: 0.936992\n",
      "Iteration 89, loss = 0.03001395\n",
      "Validation score: 0.938919\n",
      "Iteration 90, loss = 0.02992909\n",
      "Validation score: 0.940155\n",
      "Iteration 91, loss = 0.02987414\n",
      "Validation score: 0.941732\n",
      "Iteration 92, loss = 0.02919451\n",
      "Validation score: 0.940948\n",
      "Iteration 93, loss = 0.02864563\n",
      "Validation score: 0.941625\n",
      "Iteration 94, loss = 0.02824369\n",
      "Validation score: 0.940052\n",
      "Iteration 95, loss = 0.02861168\n",
      "Validation score: 0.943575\n",
      "Iteration 96, loss = 0.02779111\n",
      "Validation score: 0.944421\n",
      "Iteration 97, loss = 0.02785614\n",
      "Validation score: 0.944173\n",
      "Iteration 98, loss = 0.02786081\n",
      "Validation score: 0.944502\n",
      "Iteration 99, loss = 0.02732453\n",
      "Validation score: 0.946187\n",
      "Iteration 100, loss = 0.02627249\n",
      "Validation score: 0.943896\n",
      "Iteration 101, loss = 0.02734171\n",
      "Validation score: 0.946410\n",
      "Iteration 102, loss = 0.02623201\n",
      "Validation score: 0.946741\n",
      "Iteration 103, loss = 0.02627192\n",
      "Validation score: 0.946616\n",
      "Iteration 104, loss = 0.02554766\n",
      "Validation score: 0.948712\n",
      "Iteration 105, loss = 0.02551782\n",
      "Validation score: 0.948394\n",
      "Iteration 106, loss = 0.02521826\n",
      "Validation score: 0.949359\n",
      "Iteration 107, loss = 0.02521098\n",
      "Validation score: 0.949896\n",
      "Iteration 108, loss = 0.02480934\n",
      "Validation score: 0.949109\n",
      "Iteration 109, loss = 0.02462246\n",
      "Validation score: 0.951830\n",
      "Iteration 110, loss = 0.02415752\n",
      "Validation score: 0.950922\n",
      "Iteration 111, loss = 0.02427280\n",
      "Validation score: 0.950444\n",
      "Iteration 112, loss = 0.02404973\n",
      "Validation score: 0.953037\n",
      "Iteration 113, loss = 0.02369755\n",
      "Validation score: 0.952852\n",
      "Iteration 114, loss = 0.02344952\n",
      "Validation score: 0.953724\n",
      "Iteration 115, loss = 0.02323589\n",
      "Validation score: 0.953888\n",
      "Iteration 116, loss = 0.02279135\n",
      "Validation score: 0.955131\n",
      "Iteration 117, loss = 0.02287162\n",
      "Validation score: 0.953872\n",
      "Iteration 118, loss = 0.02260611\n",
      "Validation score: 0.955334\n",
      "Iteration 119, loss = 0.02246232\n",
      "Validation score: 0.955699\n",
      "Iteration 120, loss = 0.02265137\n",
      "Validation score: 0.956301\n",
      "Iteration 121, loss = 0.02199018\n",
      "Validation score: 0.957031\n",
      "Iteration 122, loss = 0.02176564\n",
      "Validation score: 0.956120\n",
      "Iteration 123, loss = 0.02175745\n",
      "Validation score: 0.954865\n",
      "Iteration 124, loss = 0.02151469\n",
      "Validation score: 0.956344\n",
      "Iteration 125, loss = 0.02104390\n",
      "Validation score: 0.957518\n",
      "Iteration 126, loss = 0.02093590\n",
      "Validation score: 0.958080\n",
      "Iteration 127, loss = 0.02120038\n",
      "Validation score: 0.958683\n",
      "Iteration 128, loss = 0.02052816\n",
      "Validation score: 0.958994\n",
      "Iteration 129, loss = 0.02065623\n",
      "Validation score: 0.958689\n",
      "Iteration 130, loss = 0.02059213\n",
      "Validation score: 0.958735\n",
      "Iteration 131, loss = 0.02013187\n",
      "Validation score: 0.959818\n",
      "Iteration 132, loss = 0.01997174\n",
      "Validation score: 0.960692\n",
      "Iteration 133, loss = 0.02008373\n",
      "Validation score: 0.961467\n",
      "Iteration 134, loss = 0.01987170\n",
      "Validation score: 0.959566\n",
      "Iteration 135, loss = 0.01960176\n",
      "Validation score: 0.960430\n",
      "Iteration 136, loss = 0.01997448\n",
      "Validation score: 0.960684\n",
      "Iteration 137, loss = 0.01968646\n",
      "Validation score: 0.960347\n",
      "Iteration 138, loss = 0.01939749\n",
      "Validation score: 0.961351\n",
      "Iteration 139, loss = 0.01912744\n",
      "Validation score: 0.962955\n",
      "Iteration 140, loss = 0.01894727\n",
      "Validation score: 0.962126\n",
      "Iteration 141, loss = 0.01892931\n",
      "Validation score: 0.961952\n",
      "Iteration 142, loss = 0.01863036\n",
      "Validation score: 0.962682\n",
      "Iteration 143, loss = 0.01838156\n",
      "Validation score: 0.963066\n",
      "Iteration 144, loss = 0.01821780\n",
      "Validation score: 0.963796\n",
      "Iteration 145, loss = 0.01852230\n",
      "Validation score: 0.963007\n",
      "Iteration 146, loss = 0.01851968\n",
      "Validation score: 0.959387\n",
      "Iteration 147, loss = 0.01832434\n",
      "Validation score: 0.961311\n",
      "Iteration 148, loss = 0.01802635\n",
      "Validation score: 0.963998\n",
      "Iteration 149, loss = 0.01766113\n",
      "Validation score: 0.965521\n",
      "Iteration 150, loss = 0.01790276\n",
      "Validation score: 0.962534\n",
      "Iteration 151, loss = 0.01819122\n",
      "Validation score: 0.963287\n",
      "Iteration 152, loss = 0.01767494\n",
      "Validation score: 0.964913\n",
      "Iteration 153, loss = 0.01739149\n",
      "Validation score: 0.965176\n",
      "Iteration 154, loss = 0.01722386\n",
      "Validation score: 0.966146\n",
      "Iteration 155, loss = 0.01692271\n",
      "Validation score: 0.966366\n",
      "Iteration 156, loss = 0.01725234\n",
      "Validation score: 0.966203\n",
      "Iteration 157, loss = 0.01703857\n",
      "Validation score: 0.966329\n",
      "Iteration 158, loss = 0.01668399\n",
      "Validation score: 0.967396\n",
      "Iteration 159, loss = 0.01663636\n",
      "Validation score: 0.966505\n",
      "Iteration 160, loss = 0.01643436\n",
      "Validation score: 0.967247\n",
      "Iteration 161, loss = 0.01646539\n",
      "Validation score: 0.967379\n",
      "Iteration 162, loss = 0.01629964\n",
      "Validation score: 0.968060\n",
      "Iteration 163, loss = 0.01618343\n",
      "Validation score: 0.966086\n",
      "Iteration 164, loss = 0.01646471\n",
      "Validation score: 0.966674\n",
      "Iteration 165, loss = 0.01628365\n",
      "Validation score: 0.968701\n",
      "Iteration 166, loss = 0.01571590\n",
      "Validation score: 0.965062\n",
      "Iteration 167, loss = 0.01602596\n",
      "Validation score: 0.967624\n",
      "Iteration 168, loss = 0.01615494\n",
      "Validation score: 0.967312\n",
      "Iteration 169, loss = 0.01575323\n",
      "Validation score: 0.968061\n",
      "Iteration 170, loss = 0.01547150\n",
      "Validation score: 0.967487\n",
      "Iteration 171, loss = 0.01565703\n",
      "Validation score: 0.968466\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# Espaço de busca do grid search\n",
    "min_neurons= [50, 100, 100, 100]\n",
    "max_neurons = [3000, 350, 300, 300]\n",
    "step = [5, 10, 25, 50]\n",
    "layers = [1, 2, 3, 4]\n",
    "activation =  ['relu', 'tanh']\n",
    "\n",
    "cv = ParameterSearchMLP(min_neurons = min_neurons, \n",
    "                        max_neurons = max_neurons, \n",
    "                        num_layers = layers, \n",
    "                        step = step,\n",
    "                        model = mlp, \n",
    "                        x_train = x_train,\n",
    "                        y_train = y_train,\n",
    "                        n_splits = 2\n",
    ")\n",
    "\n",
    "cv._save._path_project = os.path.abspath(Path().resolve().parent)\n",
    "cv._save._path_project\n",
    "\n",
    "cv.parameter(activation = activation)\n",
    "\n",
    "\n",
    "best_estimator = cv.RandomizedSearch(n_iter = 1, \n",
    "                                     path_cv_results = r'src\\data\\history\\parametersearch-MLP\\cv_results.csv', \n",
    "                                     path_best_params = r'src\\data\\history\\parametersearch-MLP\\best_params.csv'\n",
    "                                     \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (300, 200, 300, 300), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 chamada:591\n",
      "2 chamada: 676\n",
      "3 chamada:729\n",
      "4 chamada:625\n"
     ]
    }
   ],
   "source": [
    "print(f\"1 chamada:{len(cv.param_grid[0]['hidden_layer_sizes'])}\\n2 chamada: {len(cv.param_grid[1]['hidden_layer_sizes'])}\\n3 chamada:{len(cv.param_grid[2]['hidden_layer_sizes'])}\\n4 chamada:{len(cv.param_grid[3]['hidden_layer_sizes'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(early_stopping=True, hidden_layer_sizes=(200, 250, 275),\n",
       "             max_iter=1000, n_iter_no_change=5, random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, hidden_layer_sizes=(200, 250, 275),\n",
       "             max_iter=1000, n_iter_no_change=5, random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=(200, 250, 275),\n",
       "             max_iter=1000, n_iter_no_change=5, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv_results_\n",
    "best_estimator_\n",
    "best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit,RandomizedSearchCV,GridSearchCV\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Calcula a porcentagem relativa dos dados de treino e validação\n",
    "def size_split(size_train,size_val):\n",
    "    size_val = (1 - size_train/(size_train+size_val))\n",
    "    return size_val\n",
    "\n",
    "# Espaço de busca dos neurônios\n",
    "def space_hidden(min_neurons, max_neurons, layers, step):\n",
    "    # Lista que armazena os neurônios\n",
    "    neuron_space = []\n",
    "    neuron_combinations = []\n",
    "    \n",
    "    # Gera a lista de possíveis números de neurônios em cada camada\n",
    "    possible_neurons = list(range(min_neurons, max_neurons + 1,step))\n",
    "    \n",
    "    # Crie todas as combinações possíveis\n",
    "    for num_layers in layers:\n",
    "        neuron_combinations(list(product(possible_neurons, repeat=num_layers)))\n",
    "        \n",
    "    neuron_space.extend(neuron_combinations)\n",
    "    return neuron_space\n",
    "\n",
    "# Parâmetro da rede mlp\n",
    "def parameter_mlp(min_neurons,max_neurons,layers,step,func_act): \n",
    "    # Dicionário que armazena os hiperparâmetros\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': space_hidden(min_neurons, max_neurons,layers,step),\n",
    "        'activation': func_act\n",
    "    }\n",
    "\n",
    "    return param_grid\n",
    "\n",
    "# Random Search\n",
    "def RandomizedSearch(x, y, model, param_grid, scoring,cv, n_iter):\n",
    "    # Configura os parâmetros da técnica de otimização \n",
    "    random_search = RandomizedSearchCV(estimator=model, \n",
    "                                       param_distributions=param_grid, \n",
    "                                       scoring=scoring, \n",
    "                                       cv=cv, \n",
    "                                       n_iter=n_iter, \n",
    "                                       random_state=42, \n",
    "                                       return_train_score=True,\n",
    "                                       verbose=0)\n",
    "    \n",
    "    # Treina os modelos\n",
    "    random_search.fit(x, y)\n",
    "\n",
    "    # DataFrame que armazena os resultado dos hiperparâmetros\n",
    "    history = DataFrame(random_search.cv_results_)\n",
    "\n",
    "    # Melhor hiperparâmetro\n",
    "    best_estimator = random_search.best_estimator_\n",
    "\n",
    "    return history,best_estimator\n",
    "\n",
    "# Grid Search\n",
    "def GridSearch(x, y, model, param_grid, scoring, cv):\n",
    "    # Configura os parâmetros da técnica de otimização \n",
    "    gridshearch = GridSearchCV(estimator=model,\n",
    "                               param_grid=param_grid,\n",
    "                               cv=cv,\n",
    "                               scoring=scoring,\n",
    "                               verbose=0,\n",
    "                               return_train_score=True)\n",
    "    \n",
    "    # Treina os modelos\n",
    "    gridshearch.fit(x, y)\n",
    "    \n",
    "    # Armazena os resultado dos hiperparâmetros\n",
    "    history = DataFrame(gridshearch.cv_results_)\n",
    "    \n",
    "    best_estimator = gridshearch.best_estimator_\n",
    "\n",
    "    return history,best_estimator\n",
    "\n",
    "# Validação cruzada hold out\n",
    "def holdout(n_splits,test_size):\n",
    "    return ShuffleSplit(n_splits=n_splits, \n",
    "                      test_size=test_size, \n",
    "                      random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_hidden(min_neurons, max_neurons, layers, step):    \n",
    "    # Gera a lista de possíveis números de neurônios em cada camada\n",
    "    possible_neurons = list(range(min_neurons, max_neurons + 1,step))\n",
    "\n",
    "    return list(product(possible_neurons, repeat=layers))\n",
    "\n",
    "# Parâmetro da rede mlp\n",
    "def parameter_mlp(min_neurons,max_neurons,layers,step,func_act): \n",
    "    # Dicionário que armazena os hiperparâmetros\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': space_hidden(min_neurons, max_neurons,layers,step),\n",
    "        'activation': func_act\n",
    "    }\n",
    "\n",
    "    return param_grid\n",
    "\n",
    "# Espaço de busca do grid search\n",
    "min_neurons= 50\n",
    "max_neurons = 300\n",
    "step = 10\n",
    "layers = 2\n",
    "func_act =  ['relu', 'tanh']\n",
    "parameter_mlp(min_neurons,max_neurons,layers,step,func_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espaço de busca do grid search\n",
    "min_neurons= 50\n",
    "max_neurons = 300\n",
    "step = 10\n",
    "layers = [2,3]\n",
    "func_act =  ['relu', 'tanh']\n",
    "\n",
    "param_grid = parameter_mlp(min_neurons = min_neurons,\n",
    "                           max_neurons = max_neurons,\n",
    "                           layers=layers,\n",
    "                           step=step,\n",
    "                           func_act=func_act)\n",
    "\n",
    "len(param_grid['hidden_layer_sizes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar as métricas \n",
    "sv = save(path_project[0])\n",
    "path_data_save =  r'src\\data\\ready\\history.csv'\n",
    "\n",
    "# Dados de treino e validação\n",
    "size_val = size_split(size_train,size_val)\n",
    "\n",
    "# Espaço de busca do grid search\n",
    "min_neurons= 50\n",
    "max_neurons = 300\n",
    "step = 10\n",
    "layers = [2,3]\n",
    "func_act =  ['relu', 'tanh']\n",
    "\n",
    "param_grid = parameter_mlp(min_neurons = min_neurons,\n",
    "                           max_neurons = max_neurons,\n",
    "                           layers=layers,\n",
    "                           step=step,\n",
    "                           func_act=func_act)\n",
    "\n",
    "\n",
    "# validação cruzada hold out\n",
    "n_splits = 5\n",
    "\n",
    "# Número de amostras selecionadas no espaço de busca\n",
    "n_iter = 1000\n",
    "\n",
    "# Técnica de validação\n",
    "cv = holdout(n_splits,size_val)\n",
    "\n",
    "# inicializando a rede\n",
    "mlp = MLP()\n",
    "\n",
    "# APlicação do grid search\n",
    "history,best_model = RandomizedSearch(x=x_train, \n",
    "                           y=y_train, \n",
    "                           model=mlp, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring = 'neg_mean_squared_error', \n",
    "                           cv=cv,\n",
    "                           n_iter = n_iter)\n",
    "\n",
    "\n",
    "sv.dataframe(history,path_data_save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infomações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número de parametros de camada oculta: {len(param_grid['hidden_layer_sizes'])}\")\n",
    "print(f\"Atributos do retorno da gridsearsh: {history.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history[['mean_test_score','std_test_score','mean_train_score', 'std_train_score','params']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
